# -*- coding: utf-8 -*-
"""
AirPlug Analysis Streamlit Application
Based on analysis_for_cs.py
"""

import streamlit as st
import pymysql.cursors
import pandas as pd
import polars as pl
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import datetime
import os
import re
import math
import tempfile
import zipfile
from io import BytesIO
import urllib.request
from bs4 import BeautifulSoup
import jpholiday
import pytz
import japanize_matplotlib  # æ—¥æœ¬èªåŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’è¿½åŠ 
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
import io
import google.generativeai as genai
import PIL.Image
from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import mm
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.pdfbase.cidfonts import UnicodeCIDFont
import markdown
import urllib.request
import os

# Streamlit page configuration
st.set_page_config(
    page_title="AirPlug Analysis Dashboard",
    page_icon="ğŸŒ¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Gemini API Configuration
try:
    genai.configure(api_key='AIzaSyAbUOYuYwT2xpt0E-gps4HSzbp44iywN6I')
    GEMINI_AVAILABLE = True
except Exception as e:
    st.warning("Gemini API key configuration failed. LLM report generation will be disabled.")
    GEMINI_AVAILABLE = False

# Global variables
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None
if 'llm_report' not in st.session_state:
    st.session_state.llm_report = None
if 'llm_report_data' not in st.session_state:
    st.session_state.llm_report_data = None

# Database connection functions
def connectDB():
    """Connects to the database - creates fresh connection each time"""
    try:
        connection = pymysql.connect(
            host='gateway01.ap-northeast-1.prod.aws.tidbcloud.com',
            port=4000,
            user='2Dv1chx9hoFRkxE.analytics_user',
            password='QX7k8jm4e!M%6Pen',
            db='airplugprod',
            charset='utf8mb4',
            connect_timeout=60,
            read_timeout=60,
            write_timeout=60,
            autocommit=True,
            ssl={'ssl': {}},
            cursorclass=pymysql.cursors.DictCursor
        )
        return connection
    except Exception as e:
        st.error(f"Database connection failed: {e}")
        return None

def getDataFromDB(connection, sql, params=None):
    """Fetches data from the databaseï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    try:
        connection.ping(reconnect=True)
        
        start_time = datetime.datetime.now()
        
        with connection.cursor() as cursor:
            # ã‚ˆã‚ŠçŸ­ã„ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆ2åˆ†ï¼‰
            cursor.execute("SET SESSION max_execution_time = 120000")  # 2åˆ†
            cursor.execute("SET SESSION net_read_timeout = 120")       # 2åˆ†
            cursor.execute("SET SESSION net_write_timeout = 120")      # 2åˆ†
            
            if params:
                cursor.execute(sql, params)
            else:
                cursor.execute(sql)
            result = cursor.fetchall()
        
        end_time = datetime.datetime.now()
        execution_time = (end_time - start_time).total_seconds()
        
        # DON'T close connection here - let caller manage it
        df = pl.DataFrame(result) if result else pl.DataFrame()
        st.write(f"â±ï¸ {execution_time:.1f}ç§’ã§{len(result) if result else 0}ä»¶å–å¾—")
        return df
    except Exception as e:
        error_msg = str(e)
        if "maximum statement execution time exceeded" in error_msg:
            st.error(f"â° ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ2åˆ†è¶…éï¼‰: ãƒ‡ãƒ¼ã‚¿é‡ãŒå¤šã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        elif "timeout" in error_msg.lower():
            st.error(f"ğŸ”Œ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒä¸å®‰å®šã§ã™")
        else:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯SQLã®ä¸€éƒ¨ã®ã¿è¡¨ç¤º
        if len(sql) > 200:
            st.code(f"SQLæŠœç²‹: {sql[:200]}...")
        
        return pl.DataFrame()

# Data processing functions
def get_zone_id(floor_id):
    """Zone IDã®å–å¾—"""
    try:
        sql = "SELECT * FROM system_temperaturecontrolzone WHERE floor_id = %s"
        connection = connectDB()
        
        if connection is None:
            return pl.DataFrame(), True
            
        try:
            with connection.cursor() as cursor:
                cursor.execute(sql, (int(floor_id),))
                result = cursor.fetchall()
            
            df_id = pl.DataFrame(result) if result else pl.DataFrame()
            
            if df_id.shape[0] == 0:
                st.warning(f"No zone data found for floor_id: {floor_id}")
                return df_id, True
            
            df_id = df_id.sort("display_name")
            return df_id, False
            
        finally:
            connection.close()
        
    except Exception as e:
        st.error(f"Database error in get_zone_id: {e}")
        return pl.DataFrame(), True

def get_airid(df_id):
    """è¨­å‚™IDã®å–å¾—"""
    connection = connectDB()
    if connection is None:
        return pl.DataFrame(schema=['id', 'zone_id', 'display_name']), True
    
    try:
        if df_id.shape[0] == 0:
            sql = "SELECT * FROM system_airconditioner"
        else:
            sql = "SELECT * FROM system_airconditioner WHERE "
            for i, id in enumerate(df_id['id']):
                sql += "zone_id = '" + id + "'"
                if i < len(df_id['id']) - 1:
                    sql += " OR "

        df_airid = getDataFromDB(connection, sql)

        if df_airid.shape[0] == 0:
            return pl.DataFrame(schema=['id', 'zone_id', 'display_name']), False

        if 'zone_id' not in df_airid.columns:
            df_airid = df_airid.with_columns(pl.col('id').alias('zone_id'))

        df_airid = df_airid.sort("display_name")
        return df_airid, False
        
    except Exception as e:
        st.error(f"Error in get_airid: {e}")
        return pl.DataFrame(schema=['id', 'zone_id', 'display_name']), True
    finally:
        connection.close()

def get_df_raw_chunked(zone_ids, notBizDays, si, st_dt_ymdhms, ed_dt_ymdhms, chunk_size=5):
    """ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã«ã‚ˆã‚‹AirPlugãƒ‡ãƒ¼ã‚¿ã®å–å¾—"""
    st.write(f"ğŸ”„ {len(zone_ids)}å€‹ã®ã‚¾ãƒ¼ãƒ³IDã‚’{chunk_size}ä»¶ãšã¤å‡¦ç†ã—ã¾ã™")
    
    all_dataframes = []
    total_rows = 0
    
    for i in range(0, len(zone_ids), chunk_size):
        chunk_ids = zone_ids[i:i+chunk_size]
        chunk_num = i // chunk_size + 1
        total_chunks = (len(zone_ids) + chunk_size - 1) // chunk_size
        
        st.write(f"ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯ {chunk_num}/{total_chunks}: {len(chunk_ids)}ä»¶ã®ã‚¾ãƒ¼ãƒ³IDå‡¦ç†ä¸­...")
        
        connection = connectDB()
        if connection is None:
            st.error(f"âŒ ãƒãƒ£ãƒ³ã‚¯{chunk_num}: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã«å¤±æ•—")
            continue
            
        try:
            # æœ€é©åŒ–ã•ã‚ŒãŸSQLæ–‡ã®æ§‹ç¯‰ï¼ˆINã‚’ä½¿ç”¨ï¼‰
            zone_id_list = "', '".join(chunk_ids)
            sql = f"""
            SELECT zone_id, measured_at, value 
            FROM system_zonetemperature 
            WHERE zone_id IN ('{zone_id_list}')
            AND measured_at BETWEEN '{st_dt_ymdhms.strftime('%Y-%m-%d %H:%M:%S')}' 
            AND '{ed_dt_ymdhms.strftime('%Y-%m-%d %H:%M:%S')}'
            ORDER BY measured_at
            """
            
            st.write(f"â° ãƒãƒ£ãƒ³ã‚¯{chunk_num}: ã‚¯ã‚¨ãƒªå®Ÿè¡Œä¸­...")
            df_chunk = getDataFromDB(connection, sql)
            
            if df_chunk.shape[0] > 0:
                st.write(f"âœ… ãƒãƒ£ãƒ³ã‚¯{chunk_num}: {df_chunk.shape[0]}è¡Œå–å¾—")
                all_dataframes.append(df_chunk)
                total_rows += df_chunk.shape[0]
            else:
                st.write(f"âš ï¸ ãƒãƒ£ãƒ³ã‚¯{chunk_num}: ãƒ‡ãƒ¼ã‚¿ãªã—")
                
        except Exception as e:
            st.error(f"âŒ ãƒãƒ£ãƒ³ã‚¯{chunk_num}ã§ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            try:
                connection.close()
            except:
                pass
    
    if not all_dataframes:
        st.warning("âš ï¸ å…¨ãƒãƒ£ãƒ³ã‚¯ã§ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)]), True
    
    # å…¨ãƒãƒ£ãƒ³ã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
    st.write(f"ğŸ”„ {len(all_dataframes)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆä¸­... (åˆè¨ˆ{total_rows}è¡Œ)")
    df_combined = pl.concat(all_dataframes)
    
    return df_combined, False

def get_df_raw(df_zid, notBizDays, si, st_dt_ymdhms, ed_dt_ymdhms):
    """AirPlugãƒ‡ãƒ¼ã‚¿ã®å–å¾—ï¼ˆãƒãƒ£ãƒ³ã‚¯å‡¦ç†å¯¾å¿œç‰ˆï¼‰"""
    if df_zid.shape[0] == 0:
        st.info("Zone IDãŒ0ä»¶ã®ãŸã‚ã€ç©ºã®DataFrameã‚’è¿”ã—ã¾ã™")
        return pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)]), False

    st.write(f"ğŸ” {df_zid.shape[0]}å€‹ã®ã‚¾ãƒ¼ãƒ³IDã§ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’é–‹å§‹")
    
    # Zone IDæ•°ã«ã‚ˆã‚‹å‡¦ç†æ–¹æ³•ã®é¸æŠ
    if df_zid.shape[0] > 10:
        st.info(f"Zone IDæ•°ãŒå¤šã„ãŸã‚ã€ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚’ä½¿ç”¨ã—ã¾ã™")
        zone_ids = df_zid['id'].to_list()
        df, error = get_df_raw_chunked(zone_ids, notBizDays, si, st_dt_ymdhms, ed_dt_ymdhms, chunk_size=5)
        
        if error or df.shape[0] == 0:
            return pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)]), error
    
    else:
        # å°‘æ•°ã®å ´åˆã¯å¾“æ¥ã®æ–¹æ³•
        connection = connectDB()
        if connection is None:
            st.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ")
            return pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)]), True
            
        try:
            zone_id_list = "', '".join(df_zid['id'].to_list())
            sql = f"""
            SELECT zone_id, measured_at, value 
            FROM system_zonetemperature 
            WHERE zone_id IN ('{zone_id_list}')
            AND measured_at BETWEEN '{st_dt_ymdhms.strftime('%Y-%m-%d %H:%M:%S')}' 
            AND '{ed_dt_ymdhms.strftime('%Y-%m-%d %H:%M:%S')}'
            ORDER BY measured_at
            """
            
            st.write(f"â° ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œä¸­...")
            df = getDataFromDB(connection, sql)
            
            if df.shape[0] == 0:
                st.warning("âš ï¸ SQLã‚¯ã‚¨ãƒªã®çµæœãŒ0ä»¶ã§ã—ãŸ")
                return pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)]), True
                
        except Exception as e:
            st.error(f"âŒ get_df_raw ã§ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
            return pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)]), True
        finally:
            try:
                connection.close()
            except:
                pass
    
    try:
        st.write("ğŸ”„ ãƒ‡ãƒ¼ã‚¿å¤‰æ›ä¸­...")
        
        # æ—¥æ™‚å¤‰æ›
        df = df.with_columns(
            measured_at_jst=pl.col('measured_at').dt.offset_by(by='9h').alias('measured_at_jst')
        )

        st.write("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ”ãƒœãƒƒãƒˆä¸­...")
        
        # ãƒ”ãƒœãƒƒãƒˆå‡¦ç†
        df_pivot = df.pivot(values="value", index="measured_at_jst", on="zone_id").sort("measured_at_jst")
        
        st.write(f"ğŸ“Š ãƒ”ãƒœãƒƒãƒˆå®Œäº†: {df_pivot.shape[0]}è¡Œ Ã— {df_pivot.shape[1]}åˆ—")

        st.write(f"ğŸ”„ {si}åˆ†ã”ã¨ã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ä¸­...")
        
        # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‡¦ç†
        df_resampled = df_pivot.group_by_dynamic("measured_at_jst", every=si+"m").agg(pl.col("*").mean())
        
        st.write(f"ğŸ“Š ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Œäº†: {df_resampled.shape[0]}è¡Œ")

        st.write("ğŸ”„ å–¶æ¥­æ—¥ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ä¸­...")
        
        # å–¶æ¥­æ—¥ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        df_ex = excludeNotBizDays(df_resampled, notBizDays)
        
        st.write(f"âœ… æ¸©åº¦ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†: {df_ex.shape[0]}è¡Œ")

        return df_ex, False
        
    except Exception as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        st.code(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
        return pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)]), True

def get_df_air(df_airid, notBizDays, si, st_dt_ymdhms, ed_dt_ymdhms):
    """è¨­å‚™ãƒ‡ãƒ¼ã‚¿ã®å–å¾—"""
    connection = connectDB()
    if connection is None:
        return pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)]), True
        
    try:
        sql = "SELECT * FROM system_airconditionermeasurement WHERE (air_conditioner_id = '"
        next_str = "' OR air_conditioner_id = '"

        for id in df_airid['id']:
            sql += id + next_str

        sql = sql[:-len(next_str)] + "')"
        sql += " AND measured_at > '" + st_dt_ymdhms.strftime('%Y-%m-%d %H:%M:%S') + "' AND measured_at < '" + ed_dt_ymdhms.strftime('%Y-%m-%d %H:%M:%S') + "';"

        df = getDataFromDB(connection, sql)

        if df.is_empty():
            st.warning("Warning: get_df_air received an empty DataFrame. Returning an empty DataFrame.")
            return pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)]), False

        df = df.with_columns(
            measured_at_jst=pl.col('measured_at').dt.offset_by(by='9h').alias('measured_at_jst')
        )

        # dfã‚’pivotã—ã¦zone_idã”ã¨ã«ã‚«ãƒ©ãƒ ã«å±•é–‹
        df_pivot = df.pivot(values=["operation_mode", "fan_speed", "start_stop", "set_temperature", "process_temperature"], index="measured_at_jst", on="air_conditioner_id").sort("measured_at_jst")

        # xåˆ†ã”ã¨ã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        df_resampled_ac = df_pivot.group_by_dynamic("measured_at_jst", every=si+"m").agg(pl.col("*").mean())

        #0ã‚’null
        df_resampled_ac = df_resampled_ac.with_columns([
            pl.when(pl.col(col) == 0).then(None).otherwise(pl.col(col)).alias(col)
            for col in df_resampled_ac.columns
        ])

        df_ex = excludeNotBizDays(df_resampled_ac, notBizDays)

        return df_ex, False
        
    except Exception as e:
        st.error(f"Error in get_df_air: {e}")
        return pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)]), True
    finally:
        connection.close()

def get_df_aclog(df_airid, notBizDays, si, st_dt_ymdhms, ed_dt_ymdhms):
    """ç©ºèª¿åˆ¶å¾¡ãƒ­ã‚°ã®å–å¾—"""
    connection = connectDB()
    if connection is None:
        return pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)]), True
        
    try:
        sql = "SELECT measured_at, target_temperature, airplug_control_on, calculated_set_temperature, air_conditioner_id FROM system_airconditionerlog WHERE (air_conditioner_id = '"
        next_str = "' OR air_conditioner_id = '"

        for id in df_airid['id']:
            sql += id + next_str

        sql = sql[:-len(next_str)] + "')"
        sql += " AND measured_at > '" + st_dt_ymdhms.strftime('%Y-%m-%d %H:%M:%S') + "' AND measured_at < '" + ed_dt_ymdhms.strftime('%Y-%m-%d %H:%M:%S') + "';"

        df = getDataFromDB(connection, sql)

        if df.is_empty():
            st.warning("Warning: get_df_aclog received an empty DataFrame. Returning an empty DataFrame.")
            return pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)]), False

        df = df.with_columns(
            measured_at_jst=pl.col('measured_at').dt.offset_by(by='9h').alias('measured_at_jst')
        )

        # dfã‚’pivotã—ã¦zone_idã”ã¨ã«ã‚«ãƒ©ãƒ ã«å±•é–‹
        df_pivot = df.pivot(values=["target_temperature", "airplug_control_on", "calculated_set_temperature"], index="measured_at_jst", on="air_conditioner_id").sort("measured_at_jst")
        df_pivot = df_pivot.with_columns(pl.col('measured_at_jst').cast(pl.Datetime))

        # xåˆ†ã”ã¨ã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        df_resampled = df_pivot.group_by_dynamic("measured_at_jst", every=si+"m").agg(pl.col("*").mean())

        #ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã®ã¿æŠ½å‡º
        df_ex = excludeNotBizDays(df_resampled, notBizDays)

        return df_ex, False
        
    except Exception as e:
        st.error(f"Error in get_df_aclog: {e}")
        return pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)]), True
    finally:
        connection.close()

def get_df_target(df_airid, st_dt_ymdhms, ed_dt_ymdhms):
    """ç›®æ¨™æ¸©åº¦ã®å–å¾—"""
    connection = connectDB()
    if connection is None:
        return pl.DataFrame(schema=['measured_at_jst', 'air_conditioner_id', 'target_temperature', 'calculated_set_temperature']), True
        
    try:
        sql = "SELECT measured_at, target_temperature, airplug_control_on, calculated_set_temperature, air_conditioner_id FROM system_airconditionerlog WHERE (air_conditioner_id = '"
        next_str = "' OR air_conditioner_id = '"

        for id in df_airid['id']:
            sql += id + next_str

        sql = sql[:-len(next_str)] + "')"
        sql += " AND measured_at > '" + st_dt_ymdhms.strftime('%Y-%m-%d %H:%M:%S') + "' AND measured_at < '" + ed_dt_ymdhms.strftime('%Y-%m-%d %H:%M:%S') + "';"

        df = getDataFromDB(connection, sql)

        if df.is_empty():
            st.warning("Warning: get_df_target received an empty DataFrame. Returning an empty DataFrame with necessary columns.")
            return pl.DataFrame(schema=['measured_at_jst', 'air_conditioner_id', 'target_temperature', 'calculated_set_temperature']), False

        df = df.with_columns(
            measured_at_jst=pl.col('measured_at').dt.offset_by(by='9h').alias('measured_at_jst')
        )

        return df, False
        
    except Exception as e:
        st.error(f"Error in get_df_target: {e}")
        return pl.DataFrame(schema=['measured_at_jst', 'air_conditioner_id', 'target_temperature', 'calculated_set_temperature']), True
    finally:
        connection.close()

# Utility functions
def _getNotBizDay(st, ed):
    """ä¼‘æ—¥ã®ãƒªã‚¹ãƒˆä½œæˆ"""
    date = datetime.datetime.strptime(st, '%Y-%m-%d %H:%M:%S')
    notBizDayList = []

    while True:
        if date.weekday() == 4 or jpholiday.is_holiday(date):
            notBizDayList.append(date.strftime('%Y-%m-%d %H:%M:%S'))

        date += datetime.timedelta(days=1)

        if date > datetime.datetime.strptime(ed, '%Y-%m-%d %H:%M:%S'):
            break

    return notBizDayList

def excludeNotBizDays(df, notBizDays, exclusion_date_list=None):
    """ä¼‘æ—¥ãƒ»é™¤å¤–æ—¥ã®é™¤å¤–"""
    if df.is_empty():
        return df
        
    # notBizDaysã‹ã‚‰é™¤å¤–ã—ãŸã„æ—¥ä»˜ï¼ˆ"YYYY-MM-DD"å½¢å¼ï¼‰ã‚’æŠ½å‡º
    excluded_dates_from_notBiz = [
        datetime.datetime.strptime(ts, "%Y-%m-%d %H:%M:%S").strftime("%Y-%m-%d")
        for ts in notBizDays
    ]

    if exclusion_date_list is None:
        exclusion_date_list = []

    all_excluded_dates = set(excluded_dates_from_notBiz + exclusion_date_list)

    df = df.with_columns(pl.col("measured_at_jst").dt.strftime("%Y-%m-%d").alias("date_only"))

    # çµ±åˆã—ãŸé™¤å¤–æ—¥ãƒªã‚¹ãƒˆã«å«ã¾ã‚Œã‚‹æ—¥ä»˜ã®è¡Œã‚’é™¤å¤–
    df = df.filter(~pl.col("date_only").is_in(list(all_excluded_dates)))

    return df.drop("date_only")

def calc_res(df_airid, df_airplug, df_aircond, df_target, df_aclog, st_h, ed_h):
    """æŒ‡æ¨™ã®è¨ˆç®—"""
    df_combine = df_airplug.join(df_aircond, on='measured_at_jst', how='inner')
    df_combine = df_combine.join(df_aclog, on='measured_at_jst', how='left')

    df_combine = df_combine.filter(
        pl.col('measured_at_jst').is_not_null()
    ).filter(
        (pl.col('measured_at_jst').dt.hour() >= st_h) &
        (pl.col('measured_at_jst').dt.hour() <= ed_h)
    )

    unique_zone_ids = df_airid['zone_id'].unique().drop_nulls().to_list()

    zone_results = []

    for zone_id in unique_zone_ids:
        zone_id_str = str(zone_id)

        airconditioner_ids_in_zone = df_airid.filter(
            pl.col('zone_id') == zone_id
        )['id'].to_list()

        zone_temp_col = zone_id_str
        ac_start_cols = [f"start_stop_{ac_id}" for ac_id in airconditioner_ids_in_zone]
        ac_control_cols = [f"airplug_control_on_{ac_id}" for ac_id in airconditioner_ids_in_zone]
        ac_set_temp_cols = [f"set_temperature_{ac_id}" for ac_id in airconditioner_ids_in_zone]
        ac_target_temp_cols = [f"target_temperature_{ac_id}" for ac_id in airconditioner_ids_in_zone]

        available_zone_temp_col = zone_temp_col if zone_temp_col in df_combine.columns else None
        available_start_cols = [col for col in ac_start_cols if col in df_combine.columns]
        available_control_cols = [col for col in ac_control_cols if col in df_combine.columns]
        available_set_temp_cols = [col for col in ac_set_temp_cols if col in df_combine.columns]
        available_target_temp_cols = [col for col in ac_target_temp_cols if col in df_combine.columns]

        if not available_zone_temp_col or not available_start_cols:
            st.warning(f"è­¦å‘Š: ã‚¾ãƒ¼ãƒ³ {zone_id} ã®å¿…é ˆãƒ‡ãƒ¼ã‚¿ (æ¸©åº¦ã¾ãŸã¯é‹è»¢çŠ¶æ…‹) ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue

        zone_onoff = df_combine.select(
            pl.any_horizontal([(pl.col(col) == 1) for col in available_start_cols])
        ).to_series()

        if available_control_cols:
             zone_control = df_combine.select(
                 pl.any_horizontal([(pl.col(col).fill_null(0) == 1) for col in available_control_cols])
             ).to_series()
        else:
             zone_control = pl.repeat(False, df_combine.height, eager=True)

        mask_on = (zone_onoff & zone_control)
        mask_off = (zone_onoff & ~zone_control)
        mask_start = zone_onoff

        zone_temp_series = df_combine.select(
            pl.col(available_zone_temp_col).cast(pl.Float64)
        ).to_series()

        temp_on = zone_temp_series.filter(mask_on).to_numpy()
        temp_off = zone_temp_series.filter(mask_off).to_numpy()
        temp_start = zone_temp_series.filter(mask_start).to_numpy()

        mean_on = np.nanmean(temp_on) if len(temp_on) > 0 else np.nan
        std_on = np.nanstd(temp_on) if len(temp_on) > 0 else np.nan
        mean_off = np.nanmean(temp_off) if len(temp_off) > 0 else np.nan
        std_off = np.nanstd(temp_off) if len(temp_off) > 0 else np.nan

        total_samples = df_combine.height
        on_samples = mask_start.sum()
        on_control_on_samples = mask_on.sum()
        on_control_off_samples = mask_off.sum()

        ac_rate_on_percent = (on_control_on_samples / on_samples * 100) if on_samples > 0 else 0
        ac_rate_off_percent = (on_control_off_samples / on_samples * 100) if on_samples > 0 else 0

        e_temp_on = np.nan
        e_temp_off = np.nan
        if available_target_temp_cols:
            target_temp_series_mean = df_combine.select(
                pl.mean_horizontal([pl.col(col).cast(pl.Float64).fill_null(strategy='forward') for col in available_target_temp_cols])
            ).to_series()
            target_temp_on_np = target_temp_series_mean.filter(mask_on).to_numpy()
            target_temp_off_np = target_temp_series_mean.filter(mask_off).to_numpy()

            if len(temp_on) == len(target_temp_on_np):
                 e_temp_on = np.nanmean(np.abs(temp_on - target_temp_on_np))
            if len(temp_off) == len(target_temp_off_np):
                 e_temp_off = np.nanmean(np.abs(temp_off - target_temp_off_np))
        else:
            st.warning(f"è­¦å‘Š: ã‚¾ãƒ¼ãƒ³ {zone_id} ã®ç›®æ¨™æ¸©åº¦ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

        count_on = 0
        count_off = 0
        if available_set_temp_cols:
             df_on_changes = df_combine.filter(mask_on).select(available_set_temp_cols)
             if df_on_changes.height > 1:
                 df_on_shifted = df_on_changes.shift(1)
                 changed_on_expr = pl.any_horizontal([
                     ((pl.col(c) - df_on_shifted[c]) != 0).fill_null(False)
                     for c in available_set_temp_cols
                 ])
                 count_on = df_on_changes.select(changed_on_expr.alias("changed")).sum().row(0)[0]

             df_off_changes = df_combine.filter(mask_off).select(available_set_temp_cols)
             if df_off_changes.height > 1:
                 df_off_shifted = df_off_changes.shift(1)
                 changed_off_expr = pl.any_horizontal([
                     ((pl.col(c) - df_off_shifted[c]) != 0).fill_null(False)
                     for c in available_set_temp_cols
                 ])
                 count_off = df_off_changes.select(changed_off_expr.alias("changed")).sum().row(0)[0]
        else:
             st.warning(f"è­¦å‘Š: ã‚¾ãƒ¼ãƒ³ {zone_id} ã®è¨­å®šæ¸©åº¦ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

        null_rate_percent = df_combine[available_zone_temp_col].null_count() / total_samples * 100 if total_samples > 0 else 0

        zone_results.append([
            mean_on, mean_off, std_on, std_off,
            e_temp_on, e_temp_off, count_on, count_off,
            ac_rate_on_percent, ac_rate_off_percent, null_rate_percent
        ])

    if not zone_results:
        st.warning("è­¦å‘Š: æœ‰åŠ¹ãªã‚¾ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰çµ±è¨ˆé‡ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚NaNã‚’è¿”ã—ã¾ã™ã€‚")
        return [np.nan] * 11, df_combine

    results_array = np.array(zone_results)
    final_values = np.nanmean(results_array, axis=0).tolist()

    return final_values, df_combine

# Visualization functions
def visualize_temperature_data(df_airplug, df_aircond, df_target, df_airid):
    """æ¸©åº¦ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–"""
    if df_airplug.is_empty() or df_airid.is_empty():
        st.warning("No temperature data available for visualization.")
        return

    view_cols = ["set_temperature", "process_temperature"]
    color_list = ['orange', 'green']

    for ai, airid in enumerate(df_airid['id']):
        if df_airid['zone_id'][ai] not in df_airplug.columns:
            continue

        # ãƒ‡ãƒ¼ã‚¿ã®çµåˆ
        df_combine = df_airplug.join(df_aircond, on='measured_at_jst', how='inner')

        # offçŠ¶æ…‹ã®ãƒã‚¹ã‚¯ï¼ˆstart_stopãŒ2ã®å ´åˆï¼‰
        start_stop_col = f'start_stop_{df_airid["id"][ai]}'
        if start_stop_col in df_combine.columns:
            mask = df_combine[start_stop_col] == 2
        else:
            mask = [False] * len(df_combine)

        # ï¼‘ã¤ã®ã‚°ãƒ©ãƒ•ã«æ¸©åº¦ã¨op_modeã‚’æç”»
        fig, ax1 = plt.subplots(figsize=(15, 6))

        # é‹è»¢ãƒ¢ãƒ¼ãƒ‰ã®è‰²åˆ†ã‘
        op_mode_col = f"operation_mode_{airid}"
        if op_mode_col in df_combine.columns:
            op_mode_vals = df_combine[op_mode_col]
            op_mode_colors = [
                'grey' if off else ('cyan' if mode == 1 else ('pink' if mode == 2 else 'white'))
                for off, mode in zip(mask, op_mode_vals)
            ]
        else:
            op_mode_colors = ['blue'] * len(df_combine)

        sizes = [50 if flag else 10 for flag in mask]

        # é‹è»¢ãƒ¢ãƒ¼ãƒ‰ã®æ•£å¸ƒå›³
        ax1.scatter(
            df_combine['measured_at_jst'],
            df_combine[df_airid['zone_id'][ai]],
            s=[200 if flag else 50 for flag in mask],
            c=op_mode_colors,
            zorder=1,
            label='Operation Mode',
            alpha=0.7
        )

        # æ¸©åº¦ã®ç·šã‚°ãƒ©ãƒ•
        ax1.plot(
            df_combine['measured_at_jst'],
            df_combine[df_airid['zone_id'][ai]],
            label='Temperature',
            color='blue',
            zorder=2,
            linewidth=2
        )

        # set_temperature, process_temperature ã®æç”»
        for k, col in enumerate(view_cols):
            col_name = f'{col}_{df_airid["id"][ai]}'
            if col_name in df_combine.columns:
                ax1.plot(df_combine['measured_at_jst'], df_combine[col_name], 
                        label=col, color=color_list[k], linewidth=1)

        # ç›®æ¨™æ¸©åº¦ã®æç”»
        if not df_target.is_empty():
            df_pick = df_target.filter(pl.col("air_conditioner_id") == df_airid['id'][ai]).sort("measured_at_jst")
            if not df_pick.is_empty() and 'target_temperature' in df_pick.columns:
                ax1.plot(df_pick['measured_at_jst'], df_pick['target_temperature'],
                         label="target_temperature", color='black', linewidth=3)

        # æ¸©åº¦è»¸ã®è¨­å®š
        ax1.grid(axis="y", alpha=0.3)
        ax1.set_ylim(20, 30)
        ax1.set_xlabel("Time (JST)")
        ax1.set_ylabel("Temperature (Â°C)")
        ax1.set_title(f"Temperature Data - {df_airid['display_name'][ai]}")
        ax1.legend()

        st.pyplot(fig)
        plt.close()

def visualize_energy_summary(df_h, df_d, st_h, ed_h):
    """ã‚¨ãƒãƒ«ã‚®ãƒ¼ä½¿ç”¨é‡ã®ã‚µãƒãƒªãƒ¼å¯è¦–åŒ–"""
    if df_d.is_empty():
        st.warning("No daily energy data available.")
        return

    # æ—¥åˆ¥ã®é›»åŠ›ä½¿ç”¨é‡ã‚°ãƒ©ãƒ•
    airplug_on_cols = [col for col in df_d.columns if 'airplug_control_on' in col]
    
    if airplug_on_cols and 'Total' in df_d.columns:
        airplug_on_col = airplug_on_cols[0]
        
        # ãƒ‡ãƒ¼ã‚¿ã®åˆ†é›¢
        df_on = df_d.filter(pl.col(airplug_on_col) > 0.3)
        df_off = df_d.filter(pl.col(airplug_on_col) <= 0.3)
        
        fig, ax1 = plt.subplots(figsize=(12, 6))
        
        # AirPlug ON/OFF ã®æ£’ã‚°ãƒ©ãƒ•
        if not df_on.is_empty():
            ax1.bar(df_on['measured_at_jst'], df_on['Total'], 
                   label='AirPlug ON', color='blue', alpha=0.7)
        if not df_off.is_empty():
            ax1.bar(df_off['measured_at_jst'], df_off['Total'], 
                   label='AirPlug OFF', color='gray', alpha=0.7)
        
        # å¤–æ°—æ¸©ã®ãƒ—ãƒ­ãƒƒãƒˆï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰
        if 'outdoor_temp' in df_d.columns:
            ax2 = ax1.twinx()
            ax2.plot(df_d['measured_at_jst'], df_d['outdoor_temp'], 
                    label='Outdoor Temperature', color='red', linewidth=2)
            ax2.set_ylabel('Outdoor Temperature (Â°C)')
            ax2.legend(loc='upper right')
        
        ax1.set_xlabel('Date')
        ax1.set_ylabel('Energy Consumption (kWh)')
        ax1.set_title('Daily Energy Consumption')
        ax1.legend(loc='upper left')
        ax1.grid(alpha=0.3)
        
        st.pyplot(fig)
        plt.close()
        
        # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
        if not df_on.is_empty() and not df_off.is_empty():
            col1, col2 = st.columns(2)
            with col1:
                st.metric("AirPlug ON Average", f"{df_on['Total'].mean():.2f} kWh")
            with col2:
                st.metric("AirPlug OFF Average", f"{df_off['Total'].mean():.2f} kWh")

def display_key_metrics(values):
    """ä¸»è¦æŒ‡æ¨™ã®è¡¨ç¤º"""
    if values is None or len(values) < 11:
        st.warning("No metrics available to display.")
        return
    
    st.subheader("Key Performance Indicators")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Avg. Temp (AirPlug ON)", 
                 f"{values[0]:.2f}Â°C" if not np.isnan(values[0]) else "N/A")
        st.metric("Temp Stability (AirPlug ON)", 
                 f"{values[2]:.2f}" if not np.isnan(values[2]) else "N/A")
        st.metric("Temp Error (AirPlug ON)", 
                 f"{values[4]:.2f}Â°C" if not np.isnan(values[4]) else "N/A")
    
    with col2:
        st.metric("Avg. Temp (Conventional)", 
                 f"{values[1]:.2f}Â°C" if not np.isnan(values[1]) else "N/A")
        st.metric("Temp Stability (Conventional)", 
                 f"{values[3]:.2f}" if not np.isnan(values[3]) else "N/A")
        st.metric("Temp Error (Conventional)", 
                 f"{values[5]:.2f}Â°C" if not np.isnan(values[5]) else "N/A")
    
    with col3:
        st.metric("Manual Changes (AirPlug ON)", 
                 f"{int(values[6])}" if not np.isnan(values[6]) else "N/A")
        st.metric("Manual Changes (Conventional)", 
                 f"{int(values[7])}" if not np.isnan(values[7]) else "N/A")
        st.metric("Data Missing Rate", 
                 f"{values[10]:.1f}%" if not np.isnan(values[10]) else "N/A")

    # è©³ç´°ãªæŒ‡æ¨™è¡¨ã‚‚è¡¨ç¤º
    st.subheader("Detailed Metrics")
    metrics_df = pd.DataFrame({
        'Metric': [
            'AirPlug Mean Temperature', 'Conventional Mean Temperature',
            'AirPlug Std Temperature', 'Conventional Std Temperature', 
            'AirPlug Temperature Error', 'Conventional Temperature Error',
            'AirPlug Manual Count', 'Conventional Manual Count',
            'AirPlug Operation Rate', 'Conventional Operation Rate',
            'Data Missing Rate'
        ],
        'Value': [
            f"{values[0]:.2f}Â°C" if not np.isnan(values[0]) else "N/A",
            f"{values[1]:.2f}Â°C" if not np.isnan(values[1]) else "N/A",
            f"{values[2]:.3f}" if not np.isnan(values[2]) else "N/A",
            f"{values[3]:.3f}" if not np.isnan(values[3]) else "N/A",
            f"{values[4]:.2f}Â°C" if not np.isnan(values[4]) else "N/A",
            f"{values[5]:.2f}Â°C" if not np.isnan(values[5]) else "N/A",
            f"{int(values[6])}" if not np.isnan(values[6]) else "N/A",
            f"{int(values[7])}" if not np.isnan(values[7]) else "N/A",
            f"{values[8]:.1f}%" if not np.isnan(values[8]) else "N/A",
            f"{values[9]:.1f}%" if not np.isnan(values[9]) else "N/A",
            f"{values[10]:.1f}%" if not np.isnan(values[10]) else "N/A"
        ]
    })
    st.dataframe(metrics_df, use_container_width=True)

# Main execution function
def exec_analysis(params):
    """ãƒ¡ã‚¤ãƒ³åˆ†æå‡¦ç†"""
    try:
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å–å¾—
        floor_id = params['floor_id']
        proc_no = params['proc_no']  # è¿½åŠ 
        block_no = params['block_no']  # è¿½åŠ 
        st_dt_ymdhms = params['st_dt_ymdhms']
        ed_dt_ymdhms = params['ed_dt_ymdhms']
        st_h = params['st_h']
        ed_h = params['ed_h']
        si = params['si']
        notBizDayList = params['notBizDayList']
        
        # å¿…é ˆå¤‰æ•°ã®åˆæœŸåŒ–ï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚æœ€åˆã«åˆæœŸåŒ–ï¼‰
        df_all = pl.DataFrame()
        df_h = pl.DataFrame()
        df_d = pl.DataFrame()
        df_combine = pl.DataFrame()
        values = [np.nan] * 11
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # ã‚¹ãƒ†ãƒƒãƒ—1: ã‚¾ãƒ¼ãƒ³IDå–å¾—
        status_text.text("ã‚¹ãƒ†ãƒƒãƒ— 1/8: ã‚¾ãƒ¼ãƒ³IDã‚’å–å¾—ä¸­...")
        progress_bar.progress(10)
        
        df_zid, e_zone = get_zone_id(floor_id)
        if e_zone:
            st.error("ã‚¾ãƒ¼ãƒ³IDã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return None
            
        st.success(f"âœ… {len(df_zid)} å€‹ã®ã‚¾ãƒ¼ãƒ³ã‚’å–å¾—")
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¨ã‚¢ã‚³ãƒ³IDå–å¾—
        status_text.text("ã‚¹ãƒ†ãƒƒãƒ— 2/8: ã‚¨ã‚¢ã‚³ãƒ³IDã‚’å–å¾—ä¸­...")
        progress_bar.progress(15)
        
        df_airid, e_air = get_airid(df_zid)
        if e_air:
            st.warning("ã‚¨ã‚¢ã‚³ãƒ³IDã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
        st.success(f"âœ… {len(df_airid)} å°ã®ã‚¨ã‚¢ã‚³ãƒ³ã‚’å–å¾—")
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: æ¸©åº¦ãƒ‡ãƒ¼ã‚¿å–å¾—
        status_text.text("ã‚¹ãƒ†ãƒƒãƒ— 3/8: æ¸©åº¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        progress_bar.progress(25)
        
        df_airplug, e_temp = get_df_raw(df_zid, notBizDayList, si, st_dt_ymdhms, ed_dt_ymdhms)
        if e_temp:
            st.warning("æ¸©åº¦ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
        st.success(f"âœ… æ¸©åº¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—: {len(df_airplug)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
        
        # ã‚¹ãƒ†ãƒƒãƒ—4: ã‚¨ã‚¢ã‚³ãƒ³ãƒ‡ãƒ¼ã‚¿å–å¾—
        status_text.text("ã‚¹ãƒ†ãƒƒãƒ— 4/8: ã‚¨ã‚¢ã‚³ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        progress_bar.progress(35)
        
        df_aircond, e_aircond = get_df_air(df_airid, notBizDayList, si, st_dt_ymdhms, ed_dt_ymdhms)
        if e_aircond:
            st.warning("ã‚¨ã‚¢ã‚³ãƒ³ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
        st.success(f"âœ… ã‚¨ã‚¢ã‚³ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—: {len(df_aircond)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
        
        # ã‚¹ãƒ†ãƒƒãƒ—5: åˆ¶å¾¡ãƒ­ã‚°å–å¾—
        status_text.text("ã‚¹ãƒ†ãƒƒãƒ— 5/8: åˆ¶å¾¡ãƒ­ã‚°ã‚’å–å¾—ä¸­...")
        progress_bar.progress(45)
        
        df_aclog, e_aclog = get_df_aclog(df_airid, notBizDayList, si, st_dt_ymdhms, ed_dt_ymdhms)
        if e_aclog:
            st.warning("åˆ¶å¾¡ãƒ­ã‚°ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
        st.success(f"âœ… åˆ¶å¾¡ãƒ­ã‚°ã‚’å–å¾—: {len(df_aclog)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
        
        # ã‚¹ãƒ†ãƒƒãƒ—6: æŒ‡æ¨™è¨ˆç®—
        status_text.text("ã‚¹ãƒ†ãƒƒãƒ— 6/8: æŒ‡æ¨™ã‚’è¨ˆç®—ä¸­...")
        progress_bar.progress(55)
        
        df_target = pl.DataFrame()  # ç°¡æ˜“ç‰ˆã§ã¯ç›®æ¨™æ¸©åº¦ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—
        values, df_combine = calc_res(df_airid, df_airplug, df_aircond, df_target, df_aclog, st_h, ed_h)
        
        st.success("âœ… æŒ‡æ¨™è¨ˆç®—å®Œäº†")
        
        # ã‚¹ãƒ†ãƒƒãƒ—7: ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿å‡¦ç†
        status_text.text("ã‚¹ãƒ†ãƒƒãƒ— 7/8: ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­...")
        progress_bar.progress(65)
        
        # session_state ã‹ã‚‰ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        if hasattr(st.session_state, 'has_energy_data') and st.session_state.has_energy_data:
            energy_df = st.session_state.energy_data
            df_all, df_h, df_d = calc_energy_with_csv(st_h, ed_h, df_combine, energy_df)
            st.success("âœ… ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¾ã—ãŸ")
        else:
            df_all, df_h, df_d = calc_energy(st_h, ed_h, df_combine)
            st.info("ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ãªã—ã§å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™")
        
        # ã‚¹ãƒ†ãƒƒãƒ—8: ãƒœã‚¿ãƒ³ãƒ‡ãƒ¼ã‚¿çµ±åˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        status_text.text("ã‚¹ãƒ†ãƒƒãƒ— 8/8: ãƒœã‚¿ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆä¸­...")
        progress_bar.progress(75)
        
        try:
            if not df_all.is_empty() and not df_airid.is_empty() and not df_zid.is_empty():
                df_all, df_h, df_d = zone_bt(df_all, df_h, df_d, df_airid, df_zid, floor_id, notBizDayList, st_dt_ymdhms, ed_dt_ymdhms)
                st.success("âœ… ãƒœã‚¿ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¾ã—ãŸ")
            else:
                st.info("ãƒœã‚¿ãƒ³ãƒ‡ãƒ¼ã‚¿çµ±åˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼‰")
        except Exception as e:
            st.warning(f"ãƒœã‚¿ãƒ³ãƒ‡ãƒ¼ã‚¿çµ±åˆã§ã‚¨ãƒ©ãƒ¼: {e}")
        
        # å¤–æ°—æ¸©ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ 
        status_text.text("å¤–æ°—æ¸©ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        progress_bar.progress(85)
        
        try:
            df_all, df_h, df_d = set_out_temp(df_all, df_d, df_h, proc_no, block_no)  # proc_no, block_noã‚’æ¸¡ã™
            st.success("âœ… å¤–æ°—æ¸©ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
        except Exception as e:
            st.warning(f"å¤–æ°—æ¸©ãƒ‡ãƒ¼ã‚¿å–å¾—ã§ã‚¨ãƒ©ãƒ¼: {e}")
        
        progress_bar.progress(100)
        status_text.text("âœ… åˆ†æå®Œäº†!")
        
        # æœ€çµ‚ç¢ºèªï¼šå¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if df_all.is_empty():
            df_all = pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)])
        if df_h.is_empty():
            df_h = pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)])
        if df_d.is_empty():
            df_d = pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)])
        if df_combine.is_empty():
            df_combine = pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)])
        
        # çµæœã‚’è¿”ã™ï¼ˆè¿½åŠ ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å«ã‚€ï¼‰
        return {
            'df_all': df_all,
            'df_h': df_h, 
            'df_d': df_d,
            'df_combine': df_combine,
            'df_airid': df_airid,
            'df_zid': df_zid,
            'df_airplug': df_airplug,  # è¿½åŠ 
            'df_aircond': df_aircond,  # è¿½åŠ 
            'df_target': df_target,    # è¿½åŠ 
            'df_aclog': df_aclog,      # è¿½åŠ 
            'values': values
        }
        
    except Exception as e:
        st.error(f"åˆ†æå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        st.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
        return None

# Streamlit UI
def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    st.title("AirPlugåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    st.markdown("---")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å…¥åŠ›
    st.sidebar.title("åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    
    # é¡§å®¢æƒ…å ±
    st.sidebar.subheader("é¡§å®¢æƒ…å ±")
    customer_dir = st.sidebar.text_input("é¡§å®¢ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª", value="/æ±äº¬å»ºç‰©/æ—¥æœ¬æ©‹ãƒ“ãƒ«/10F")
    add_dir = st.sidebar.text_input("è¿½åŠ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª", value="/raw_data")
    sumit_id = st.sidebar.text_input("Summit ID", value="120005")
    floor_id = st.sidebar.text_input("ãƒ•ãƒ­ã‚¢ID", value="210002")
    floor_name = st.sidebar.text_input("ãƒ•ãƒ­ã‚¢å", value="10F")
    
    # ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
    st.sidebar.subheader("ã‚·ã‚¹ãƒ†ãƒ è¨­å®š")
    sys_kind = st.sidebar.selectbox("ã‚·ã‚¹ãƒ†ãƒ ç¨®åˆ¥", ["plus", "slim"], index=0)
    energy_kind = st.sidebar.selectbox("ã‚¨ãƒãƒ«ã‚®ãƒ¼ç¨®åˆ¥", ["master"], index=0)
    energy_format_type = st.sidebar.selectbox("ã‚¨ãƒãƒ«ã‚®ãƒ¼å½¢å¼", ["mufg", "PRT", "dk", "hioki_local", "hioki_cloud"], index=1)
    
    # å¤–æ°—æ¸©ãƒ‡ãƒ¼ã‚¿è¨­å®š
    st.sidebar.subheader("å¤–æ°—æ¸©ãƒ‡ãƒ¼ã‚¿è¨­å®š")
    proc_no = st.sidebar.number_input("éƒ½é“åºœçœŒç•ªå· (proc_no)", value=44, min_value=1, max_value=100)
    block_no = st.sidebar.number_input("ã‚¨ãƒªã‚¢ç•ªå· (block_no)", value=47662, min_value=1, max_value=99999)
    
    # åˆ†ææœŸé–“
    st.sidebar.subheader("åˆ†ææœŸé–“")
    today = datetime.date.today()
    
    # æ—¥ä»˜ã¨æ™‚é–“ã®å…¥åŠ›
    st_date = st.sidebar.date_input("é–‹å§‹æ—¥", datetime.date(2025, 2, 10))
    st_time = st.sidebar.time_input("é–‹å§‹æ™‚åˆ»", datetime.time(8, 0, 0))
    st_dt = datetime.datetime.combine(st_date, st_time)
    
    ed_date = st.sidebar.date_input("çµ‚äº†æ—¥", datetime.date(2025, 3, 7))
    ed_time = st.sidebar.time_input("çµ‚äº†æ™‚åˆ»", datetime.time(18, 0, 0))
    ed_dt = datetime.datetime.combine(ed_date, ed_time)
    
    # æ™‚é–“å¸¯è¨­å®š
    st.sidebar.subheader("åˆ†ææ™‚é–“å¸¯")
    st_h = st.sidebar.slider("é–‹å§‹æ™‚é–“", 0, 23, 8)
    ed_h = st.sidebar.slider("çµ‚äº†æ™‚é–“", 0, 23, 18)
    
    # é™¤å¤–æ—¥è¨­å®š
    st.sidebar.subheader("é™¤å¤–æ—¥è¨­å®š")
    exclusion_dates = st.sidebar.text_area(
        "é™¤å¤–æ—¥ï¼ˆ1è¡Œã«1æ—¥ã€YYYY-MM-DDå½¢å¼ï¼‰",
        value=""
    )
    
    exclusion_date_list = []
    if exclusion_dates.strip():
        exclusion_date_list = [date.strip() for date in exclusion_dates.strip().split('\n') if date.strip()]
    
    st.session_state['exclusion_date_list'] = exclusion_date_list
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¾‹ã®è¡¨ç¤º
    with st.sidebar.expander("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¾‹"):
        st.code("""
# KONAMIã‚¹ãƒãƒ¼ãƒ„ã‚¯ãƒ©ãƒ–ï¼ˆMiddle POCï¼‰ã®ä¾‹
customer_dir='/KONAMIã‚¹ãƒãƒ¼ãƒ„ã‚¯ãƒ©ãƒ–ï¼ˆMiddle POCï¼‰/3F'
add_dir='/Data'
sumit_id="630001"
floor_id="630001" 
proc_no=44  # æ±äº¬
block_no=47662  # æ±äº¬
floor_name="3F"
st_dt='2025-05-24 00:00:00'
ed_dt='2025-06-06 23:00:00'
st_h=10
ed_h=23
sys_kind='plus'
energy_format_type='mufg'

# é‡æ‘ä¸å‹•ç”£ã®ä¾‹
customer_dir='/é‡æ‘ä¸å‹•ç”£'
add_dir='/Data'
sumit_id="210007"
floor_id="300003"
proc_no=44  # æ±äº¬
block_no=47662  # æ±äº¬
floor_name="2F"
st_dt='2025-02-03 00:00:00'
ed_dt='2025-02-14 23:59:00'
st_h=8
ed_h=20
sys_kind='plus'
energy_format_type='dk'

# ç¥æˆ¸ã‚¢ã‚¤ã‚»ãƒ³ã‚¿ãƒ¼ã®ä¾‹
customer_dir='/ç¥æˆ¸ã‚¢ã‚¤ã‚»ãƒ³ã‚¿ãƒ¼ï¼ˆMiddle POCï¼‰/4F'
add_dir='/Data'
sumit_id='600001'
floor_id='600001'
proc_no=63  # å…µåº«
block_no=1587  # ç¥æˆ¸
floor_name='4F'
st_dt='2025-05-10 13:59:00'
ed_dt='2025-05-10 15:25:00'
st_h=9
ed_h=17
sys_kind='plus'
energy_format_type='mufg'
        """)
    
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    if 'analysis_results' not in st.session_state:
        st.session_state.analysis_results = None
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¾æ›¸ä½œæˆï¼ˆå¸¸ã«ä½œæˆã—ã¦ä¿å­˜ç”¨ï¼‰
    notBizDayList = _getNotBizDay(st_dt.strftime('%Y-%m-%d %H:%M:%S'), ed_dt.strftime('%Y-%m-%d %H:%M:%S'))
    
    current_params = {
        'customer_dir': customer_dir,
        'add_dir': add_dir,
        'sumit_id': sumit_id,
        'floor_id': floor_id,
        'floor_name': floor_name,
        'sys_kind': sys_kind,
        'energy_kind': energy_kind,
        'energy_format_type': energy_format_type,
        'proc_no': proc_no,
        'block_no': block_no,
        'st_dt_ymdhms': st_dt,
        'ed_dt_ymdhms': ed_dt,
        'st_h': st_h,
        'ed_h': ed_h,
        'si': '1',
        'notBizDayList': notBizDayList
    }
    
    # ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆ†æå®Ÿè¡Œãƒœã‚¿ãƒ³ã®å‰ã«è¡¨ç¤ºï¼‰
    st.sidebar.subheader("ğŸ“Š ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿")
    energy_df, has_energy = get_energy_data(current_params)
    
    # ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ session_state ã«ä¿å­˜
    if has_energy and energy_df is not None and not energy_df.is_empty():
        st.session_state.energy_data = energy_df
        st.session_state.has_energy_data = True
        st.sidebar.success("âœ… ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†")
    else:
        st.session_state.energy_data = None
        st.session_state.has_energy_data = False
        if 'energy_data' in st.session_state:
            del st.session_state.energy_data
    
    # åˆ†æå®Ÿè¡Œãƒœã‚¿ãƒ³
    if st.sidebar.button("åˆ†æå®Ÿè¡Œ", type="primary", key="execute_analysis"):
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼
        if not floor_id.strip():
            st.error("ãƒ•ãƒ­ã‚¢IDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return
            
        if st_dt >= ed_dt:
            st.error("é–‹å§‹æ—¥æ™‚ã¯çµ‚äº†æ—¥æ™‚ã‚ˆã‚Šå‰ã«è¨­å®šã—ã¦ãã ã•ã„")
            return
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¡¨ç¤º
        with st.expander("å®Ÿè¡Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"):
            col1, col2 = st.columns(2)
            with col1:
                st.write("**åŸºæœ¬è¨­å®š**")
                st.write(f"customer_dir: {customer_dir}")
                st.write(f"floor_name: {floor_name} (floor_id: {floor_id})")
                st.write(f"sys_kind: {sys_kind}")
                st.write(f"energy_format_type: {energy_format_type}")
                st.write(f"proc_no: {proc_no}, block_no: {block_no}")
            with col2:
                st.write("**æœŸé–“è¨­å®š**")
                st.write(f"st_dt: '{st_dt.strftime('%Y-%m-%d %H:%M:%S')}'")
                st.write(f"ed_dt: '{ed_dt.strftime('%Y-%m-%d %H:%M:%S')}'")
                st.write(f"st_h: {st_h}, ed_h: {ed_h}")
                st.write(f"é™¤å¤–æ—¥: {len(exclusion_date_list)}æ—¥")
        
        # åˆ†æå®Ÿè¡Œ
        results = exec_analysis(current_params)
        
        if results:
            st.session_state.analysis_results = results
            st.session_state.analysis_params = current_params
            
            # åˆ†æçµæœè¡¨ç¤º
            display_analysis_results(results, current_params)
    
    # æ—¢å­˜ã®åˆ†æçµæœãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
    elif st.session_state.analysis_results is not None:
        # ä¿å­˜ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        saved_params = st.session_state.get('analysis_params', current_params)
        display_analysis_results(st.session_state.analysis_results, saved_params)
    
    else:
        # åˆæœŸè¡¨ç¤ºï¼ˆåˆ†æçµæœãŒãªã„å ´åˆã®ã¿ï¼‰
        st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã—ã€ã€Œåˆ†æå®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ
        st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ")
        if st.button("æ¥ç¶šãƒ†ã‚¹ãƒˆå®Ÿè¡Œ", key="db_connection_test"):
            with st.spinner("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šä¸­..."):
                connection = connectDB()
                if connection:
                    try:
                        with connection.cursor() as cursor:
                            cursor.execute("SELECT COUNT(*) as total FROM system_temperaturecontrolzone")
                            result = cursor.fetchone()
                        connection.close()
                        st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæˆåŠŸï¼ã‚¾ãƒ¼ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {result['total']}")
                    except Exception as e:
                        st.error(f"âŒ ã‚¯ã‚¨ãƒªå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
                else:
                    st.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ")

def test_database_connection():
    """Test database connection and show available data"""
    with st.spinner("Testing database connection..."):
        try:
            connection = connectDB()
            if connection is None:
                st.error("âŒ Failed to connect to database")
                return
                
            try:
                # Test basic query
                with connection.cursor() as cursor:
                    cursor.execute("SELECT COUNT(*) as total FROM system_temperaturecontrolzone")
                    total_zones = cursor.fetchone()['total']
                    
                    cursor.execute("SELECT DISTINCT floor_id FROM system_temperaturecontrolzone LIMIT 10")
                    floors = cursor.fetchall()
                
                st.success(f"âœ… Database connection successful!")
                st.info(f"Total zones in database: {total_zones}")
                
                if floors:
                    st.write("**Available Floor IDs (sample):**")
                    floor_df = pd.DataFrame(floors)
                    st.dataframe(floor_df, use_container_width=True)
                    
            finally:
                connection.close()
            
        except Exception as e:
            st.error(f"âŒ Database connection failed: {e}")

def generate_analysis_report(results):
    """Generate a text report of the analysis results"""
    params = results['params']
    values = results['values']
    
    report = f"""
AirPlug Analysis Report
=======================

Analysis Parameters:
-------------------
Customer: {params['customer_dir']}
Floor: {params['floor_name']} (ID: {params['floor_id']})
Period: {params['st_dt_ymdhms'].strftime('%Y-%m-%d %H:%M')} to {params['ed_dt_ymdhms'].strftime('%Y-%m-%d %H:%M')}
Analysis Hours: {params['st_h']}:00 - {params['ed_h']}:00
System Type: {params['sys_kind']}

Key Performance Indicators:
---------------------------
Average Temperature (AirPlug ON): {values[0]:.2f}Â°C
Average Temperature (Conventional): {values[1]:.2f}Â°C
Temperature Stability (AirPlug ON): {values[2]:.3f}
Temperature Stability (Conventional): {values[3]:.3f}
Temperature Error (AirPlug ON): {values[4]:.2f}Â°C
Temperature Error (Conventional): {values[5]:.2f}Â°C
Manual Changes (AirPlug ON): {int(values[6])}
Manual Changes (Conventional): {int(values[7])}
Operation Rate (AirPlug ON): {values[8]:.1f}%
Operation Rate (Conventional): {values[9]:.1f}%
Data Missing Rate: {values[10]:.1f}%

Data Summary:
-------------
Zones Found: {len(results['df_zid']) if not results['df_zid'].is_empty() else 0}
Air Conditioners: {len(results['df_airid']) if not results['df_airid'].is_empty() else 0}
Temperature Records: {len(results['df_airplug']) if not results['df_airplug'].is_empty() else 0}
AC Measurement Records: {len(results['df_aircond']) if not results['df_aircond'].is_empty() else 0}

Analysis Summary:
-----------------
Temperature Improvement: {values[1] - values[0]:.2f}Â°C (Conventional - AirPlug)
Stability Improvement: {values[3] - values[2]:.3f} (Conventional - AirPlug)
Manual Operation Reduction: {int(values[7] - values[6])} changes

Generated on: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
    return report

# CSVå‡¦ç†é–¢æ•°ï¼ˆã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨ã€å¿…è¦ã«å¿œã˜ã¦ï¼‰
def process_energy_csv(uploaded_file, energy_format_type):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚¨ãƒãƒ«ã‚®ãƒ¼CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†"""
    try:
        if energy_format_type == "hioki":
            df = pd.read_csv(uploaded_file, skiprows=26, na_values=["-"])
            df = df.iloc[:, 3:]  # æœ€åˆã®3åˆ—ã‚’ã‚¹ã‚­ãƒƒãƒ—
        elif energy_format_type == "master":
            df = pd.read_csv(uploaded_file, na_values=["-"])
            df = df.iloc[:, 2:]  # æœ€åˆã®2åˆ—ã‚’ã‚¹ã‚­ãƒƒãƒ—
        else:
            df = pd.read_csv(uploaded_file)
        
        return df
    except Exception as e:
        st.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# è¿½åŠ ã®ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•°

def get_df_bt(notBizDays, si, sign, fid, st_dt_ymdhms, ed_dt_ymdhms):
    """ãƒœã‚¿ãƒ³ãƒ‡ãƒ¼ã‚¿ã®å–å¾—"""
    connection = connectDB()
    if connection is None:
        return pl.DataFrame(), True
        
    try:
        if sign == '+':
            sql = "SELECT * FROM system_devicemeasurementbuttonplus WHERE value != 0 AND floor_id ='" + fid + "'"
        else:
            sql = "SELECT * FROM system_devicemeasurementbuttonminus WHERE value != 0 AND floor_id ='" + fid + "'"

        sql += " AND measured_at > '" + st_dt_ymdhms.strftime('%Y-%m-%d %H:%M:%S') + "' AND measured_at < '" + ed_dt_ymdhms.strftime('%Y-%m-%d %H:%M:%S') + "';"

        df = getDataFromDB(connection, sql)

        if df.shape[0] == 0:
            return df, True

        df = df.filter(pl.col('value') < 10)

        if df.shape[0] == 0:
            return df, True

        df = df.with_columns(
            measured_at_jst=pl.col('measured_at').dt.offset_by(by='9h').alias('measured_at_jst')
        )

        df_ex = excludeNotBizDays(df, notBizDays)

        return df, False
        
    except Exception as e:
        st.error(f"get_df_btã§ã‚¨ãƒ©ãƒ¼: {e}")
        return pl.DataFrame(), True
    finally:
        connection.close()


def zone_bt(df_all, df_h, df_d, df_airid, df_zid, floor_id, notBizDayList, st_dt_ymdhms, ed_dt_ymdhms):
    """ãƒœã‚¿ãƒ³ãƒ‡ãƒ¼ã‚¿çµ±åˆï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    try:
        # ç°¡æ˜“ç‰ˆã§ã¯å®Ÿéš›ã®ãƒœã‚¿ãƒ³ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã€å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãã®ã¾ã¾è¿”ã™
        return df_all, df_h, df_d
    except Exception as e:
        st.warning(f"ãƒœã‚¿ãƒ³ãƒ‡ãƒ¼ã‚¿çµ±åˆå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
        return df_all, df_h, df_d

def set_out_temp(df_all, df_d, df_h, proc_no=44, block_no=47662):
    """å¤–æ°—æ¸©ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€proc_noã¨block_noã‚’ä½¿ã£ã¦æ°—è±¡åºã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    # ç¾åœ¨ã¯ç°¡æ˜“ç‰ˆã®ãŸã‚ã€å˜ã«ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ã™ã‚‹ã®ã¿
    try:
        # å¤–æ°—æ¸©ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯è¿½åŠ 
        if not df_all.is_empty() and 'outdoor_temp' not in df_all.columns:
            df_all = df_all.with_columns(pl.lit(None).cast(pl.Float64).alias('outdoor_temp'))
        if not df_h.is_empty() and 'outdoor_temp' not in df_h.columns:
            df_h = df_h.with_columns(pl.lit(None).cast(pl.Float64).alias('outdoor_temp'))
        if not df_d.is_empty() and 'outdoor_temp' not in df_d.columns:
            df_d = df_d.with_columns(pl.lit(None).cast(pl.Float64).alias('outdoor_temp'))
        
        return df_all, df_h, df_d
    except Exception as e:
        st.warning(f"å¤–æ°—æ¸©ãƒ‡ãƒ¼ã‚¿è¿½åŠ å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
        return df_all, df_h, df_d

def calc_energy(st_h, ed_h, df_combine):
    """ã‚¨ãƒãƒ«ã‚®ãƒ¼è¨ˆç®—ï¼ˆCSVç„¡ã—ã®å ´åˆã®ãƒ€ãƒŸãƒ¼å‡¦ç†ï¼‰"""
    try:
        if df_combine.is_empty():
            # ç©ºã®DataFrameã®å ´åˆ
            df_all = pl.DataFrame(schema=[('measured_at_jst', pl.Datetime), ('Total', pl.Float64)])
            df_h = pl.DataFrame(schema=[('measured_at_jst', pl.Datetime), ('Total', pl.Float64)])
            df_d = pl.DataFrame(schema=[('measured_at_jst', pl.Datetime), ('Total', pl.Float64)])
        else:
            # df_combineã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
            df_all = df_combine.clone()
            
            # æ™‚é–“ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            df_all = df_all.filter(
                (pl.col('measured_at_jst').dt.hour() >= st_h) &
                (pl.col('measured_at_jst').dt.hour() <= ed_h)
            )
            
            # æ™‚é–“åˆ¥ãƒ»æ—¥åˆ¥é›†è¨ˆ
            if 'measured_at_jst' in df_all.columns and not df_all.is_empty():
                df_h = df_all.group_by_dynamic("measured_at_jst", every="1h").agg(pl.col("*").mean())
                df_d = df_h.group_by_dynamic("measured_at_jst", every="1d").agg(pl.col("*").sum())
            else:
                df_h = pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)])
                df_d = pl.DataFrame(schema=[('measured_at_jst', pl.Datetime)])
            
            # Totalã‚«ãƒ©ãƒ ã‚’è¿½åŠ ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
            if 'Total' not in df_all.columns:
                df_all = df_all.with_columns(pl.lit(0.0).alias('Total'))
            if not df_h.is_empty() and 'Total' not in df_h.columns:
                df_h = df_h.with_columns(pl.lit(0.0).alias('Total'))
            if not df_d.is_empty() and 'Total' not in df_d.columns:
                df_d = df_d.with_columns(pl.lit(0.0).alias('Total'))
        
        return df_all, df_h, df_d
        
    except Exception as e:
        st.warning(f"ã‚¨ãƒãƒ«ã‚®ãƒ¼è¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        df_all = pl.DataFrame(schema=[('measured_at_jst', pl.Datetime), ('Total', pl.Float64)])
        df_h = pl.DataFrame(schema=[('measured_at_jst', pl.Datetime), ('Total', pl.Float64)])
        df_d = pl.DataFrame(schema=[('measured_at_jst', pl.Datetime), ('Total', pl.Float64)])
        return df_all, df_h, df_d

def str2float(weather_data):
    """å¤©æ°—ãƒ‡ãƒ¼ã‚¿ã‚’æµ®å‹•å°æ•°ç‚¹ã«å¤‰æ›"""
    try:
        return float(weather_data)
    except:
        return 0

def scraping(url, date, data_type):
    """æ°—è±¡ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""
    try:
        html = urllib.request.urlopen(url).read()
        soup = BeautifulSoup(html, 'html.parser')
        trs = soup.find("table", {"class": "data2_s"})
        if trs is None:
            st.warning(f"Failed to find data table for {data_type} on {date}. URL: {url}")
            return []
        data_list_per_hour = []
        for tr in trs.findAll('tr')[2:]:
            tds = tr.findAll('td')

            if int(tds[0].string[:2]) != 24:
              dt = datetime.datetime(date.year, date.month, date.day, int(tds[0].string[:2]), int(tds[0].string[3:5]))
            else:
              dt = datetime.datetime(date.year, date.month, date.day, 0, int(tds[0].string[3:5])) + datetime.timedelta(days=1)

            if not tds or tds[1].string is None:
                break
            if data_type == 'temperature':
                data_list = [dt, str2float(tds[4].string)]
            elif data_type == 'solar':
                data_list = [dt, str2float(tds[11].string)]
            data_list_per_hour.append(data_list)
        return data_list_per_hour
    except Exception as e:
        st.warning(f"æ°—è±¡ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def visualize_bt(df_all, df_h, df_d, df_airid, st_h, ed_h):
    """ãƒœã‚¿ãƒ³ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—å¯è¦–åŒ–"""
    if df_h.is_empty():
        st.warning("ãƒœã‚¿ãƒ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
        
    visualize_date = df_h.with_columns(pl.col('measured_at_jst').dt.date()).select(pl.col('measured_at_jst')).unique()

    for di in range(len(visualize_date)):
        df = df_h.filter(pl.col('measured_at_jst').dt.date() == visualize_date[di])
        bt_cols = [col for col in df.columns if col.startswith('bt_')]
        
        if not bt_cols:
            continue
            
        df = df.select(['measured_at_jst'] + bt_cols)

        tmp = df.drop('measured_at_jst').to_numpy().T

        fig, ax = plt.subplots(figsize=(12, 6))
        im = ax.imshow(tmp, extent=(st_h, ed_h+1, len(bt_cols), 0), cmap='seismic_r', aspect=0.25)
        plt.colorbar(im, shrink=0.5)
        plt.clim(-10, 10)
        
        ax.set_title(f'ãƒœã‚¿ãƒ³æ“ä½œãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— - {visualize_date[di].to_numpy()[0]}')
        ax.set_xlabel('æ™‚åˆ»')
        ax.set_ylabel('ã‚¾ãƒ¼ãƒ³')
        
        st.pyplot(fig)
        plt.close()

def calc_bt(df_all, df_d, df_h, df_airid):
    """ãƒœã‚¿ãƒ³ã®çµæœæ¼”ç®—"""
    if df_d.is_empty() or df_all.is_empty():
        st.warning("ãƒœã‚¿ãƒ³çµ±è¨ˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
        
    day_list = df_d.select(pl.col('measured_at_jst').dt.date().unique()).to_series().to_list()
    bt_cols = [col for col in df_all.columns if col.startswith('bt_')]
    airplug_cols = [col for col in df_all.columns if 'airplug_control_on' in col]
    
    if not bt_cols:
        st.warning("ãƒœã‚¿ãƒ³ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
        
    df_df = df_all.select(['measured_at_jst'] + airplug_cols + bt_cols)

    st.subheader("ğŸ“± ãƒœã‚¿ãƒ³æ“ä½œçµ±è¨ˆ")
    
    summary_data = []
    
    for di in range(len(day_list)):
        df = df_df.filter(pl.col('measured_at_jst').dt.date() == day_list[di])

        bt_array = df.select(bt_cols).to_numpy()
        mask_p = bt_array > 0
        mask_m = bt_array < 0

        btp = bt_array[mask_p]
        btm = bt_array[mask_m]

        summary_data.append({
            'æ—¥ä»˜': day_list[di],
            '+æ“ä½œå›æ•°': int(np.sum(btp)) if len(btp) > 0 else 0,
            '-æ“ä½œå›æ•°': int(np.sum(btm)) if len(btm) > 0 else 0,
            '+æ“ä½œé »åº¦': len(btp),
            '-æ“ä½œé »åº¦': len(btm)
        })

    if summary_data:
        st.dataframe(pd.DataFrame(summary_data), use_container_width=True)

def visualize_remote_control(df_all, df_h, df_d, st_dt, ed_dt):
    """ãƒªãƒ¢ã‚³ãƒ³æ“ä½œã®å¯è¦–åŒ–"""
    if df_all.is_empty():
        st.warning("ãƒªãƒ¢ã‚³ãƒ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
        
    temp_df = df_all.to_pandas()
    temp_df['measured_at_jst'] = pd.to_datetime(temp_df['measured_at_jst'])
    set_temperature_columns = [col for col in df_all.columns if col.startswith("set_temperature_")]

    if not set_temperature_columns:
        st.warning("'set_temperature_' ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒªãƒ¢ã‚³ãƒ³æ“ä½œã®å¯è¦–åŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return

    # å„ã‚«ãƒ©ãƒ ã”ã¨ã«æœ€å°å€¤ã¨æœ€å¤§å€¤ã‚’å–å¾—
    y_min = min([temp_df[col].min() for col in set_temperature_columns]) - 1
    y_max = max([temp_df[col].max() for col in set_temperature_columns]) + 1

    date_range = pd.date_range(start=st_dt, end=ed_dt)
    daily_summary = []

    # ãƒ—ãƒ­ãƒƒãƒˆæ•°ã«å¿œã˜ãŸã‚°ãƒªãƒƒãƒ‰ã®è¡Œæ•°ãƒ»åˆ—æ•°ã‚’è‡ªå‹•è¨ˆç®—
    n_plots_dt_range = len(date_range)
    n_cols_dt_range = math.ceil(math.sqrt(n_plots_dt_range))
    n_rows_dt_range = math.ceil(n_plots_dt_range / n_cols_dt_range)

    # å„æ—¥ä»˜ã®å„æ™‚é–“å¸¯ã«ãŠã‘ã‚‹æ¸©åº¦ä¸Šæ˜‡ã¨ä¸‹é™ã®æ‰‹å‹•å¤‰æ›´å›æ•°ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    fig, axes = plt.subplots(n_rows_dt_range, n_cols_dt_range, figsize=(18, n_rows_dt_range * 5))

    if n_plots_dt_range == 1:
        axes = [axes]
    elif n_rows_dt_range == 1:
        axes = [axes]
    else:
        axes = axes.flatten()

    # å„æ—¥ä»˜ã«ã¤ã„ã¦å‡¦ç†
    for idx, date in enumerate(date_range):
        if idx >= len(axes):
            break
            
        ax = axes[idx]
        date_data = temp_df[temp_df['measured_at_jst'].dt.date == date.date()]

        manual_up_count = 0
        manual_down_count = 0

        # å„è¨­å®šæ¸©åº¦ã‚«ãƒ©ãƒ ã«ã¤ã„ã¦å‡¦ç†
        for col in set_temperature_columns:
            if col in date_data.columns:
                # å‰ã®æ™‚é–“å¸¯ã¨ã®å·®ã‚’è¨ˆç®—
                temp_diff = date_data[col].diff()

                # æ‰‹å‹•å¤‰æ›´ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                manual_up_count += temp_diff[temp_diff == 0.5].count()
                manual_down_count += temp_diff[temp_diff == -0.5].count()

        # daily_summary ã«æ—¥ä»˜ã¨æ‰‹å‹•å¤‰æ›´å›æ•°ã‚’è¿½åŠ 
        daily_summary.append({
            'æ—¥ä»˜': date.date(), 
            'æ‰‹å‹•ä¸Šæ˜‡': manual_up_count, 
            'æ‰‹å‹•ä¸‹é™': manual_down_count
        })

        # æ™‚é–“åˆ¥ã®å¤‰æ›´å›æ•°ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
        hourly_up_changes = pd.Series(0, index=pd.date_range(date, periods=24, freq='h'))
        hourly_down_changes = pd.Series(0, index=pd.date_range(date, periods=24, freq='h'))

        if not date_data.empty:
            for room in set_temperature_columns:
                if room in date_data.columns:
                    temperature_data = date_data[['measured_at_jst', room]].copy()
                    temperature_data.rename(columns={room: 'set_temperature'}, inplace=True)
                    temperature_data['temp_change'] = temperature_data['set_temperature'].diff()

                    temperature_data['manual_up'] = (
                        (temperature_data['temp_change'] > 0) &
                        (temperature_data['temp_change'] % 0.5 == 0)
                    )
                    temperature_data['manual_down'] = (
                        (temperature_data['temp_change'] < 0) &
                        (temperature_data['temp_change'] % 0.5 == 0)
                    )

                    temperature_data['hour'] = temperature_data['measured_at_jst'].dt.floor('h')
                    hourly_up = temperature_data.groupby('hour')['manual_up'].sum()
                    hourly_down = temperature_data.groupby('hour')['manual_down'].sum()

                    hourly_up_changes = hourly_up_changes.add(hourly_up, fill_value=0)
                    hourly_down_changes = hourly_down_changes.add(hourly_down, fill_value=0)

        ax.plot(hourly_up_changes.index, hourly_up_changes.values, marker='o', color='red', label='æ‰‹å‹•ä¸Šæ˜‡ (+0.5)')
        ax.plot(hourly_down_changes.index, hourly_down_changes.values, marker='o', color='blue', label='æ‰‹å‹•ä¸‹é™ (-0.5)')
        ax.set_title(f'{date.strftime("%Y-%m-%d")}', fontsize=12)
        ax.set_xlabel('æ™‚åˆ»', fontsize=10)
        ax.set_ylabel('æ‰‹å‹•å¤‰æ›´å›æ•°', fontsize=10)
        ax.grid(True, linestyle='--', alpha=0.7)
        ax.legend(fontsize=8)
        ax.tick_params(axis='x', rotation=45)
        ax.set_ylim(0, max(hourly_up_changes.max(), hourly_down_changes.max(), 5))

    # ç©ºã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’å‰Šé™¤
    for idx in range(len(date_range), len(axes)):
        fig.delaxes(axes[idx])

    plt.tight_layout()
    st.pyplot(fig)
    plt.close()

    # æ—¥åˆ¥æ‰‹å‹•å¤‰æ›´ã®å¤‰å‹•ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    daily_summary_df = pd.DataFrame(daily_summary)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.plot(daily_summary_df['æ—¥ä»˜'], daily_summary_df['æ‰‹å‹•ä¸Šæ˜‡'], marker='o', linestyle='-', color='red', label='æ‰‹å‹•ä¸Šæ˜‡ (+0.5)')
    ax.plot(daily_summary_df['æ—¥ä»˜'], daily_summary_df['æ‰‹å‹•ä¸‹é™'], marker='o', linestyle='-', color='blue', label='æ‰‹å‹•ä¸‹é™ (-0.5)')
    ax.set_xlabel('æ—¥ä»˜')
    ax.set_ylabel('å›æ•°')
    ax.set_title('æ—¥åˆ¥æ‰‹å‹•æ¸©åº¦å¤‰æ›´å›æ•°')
    ax.grid(True)
    ax.legend()
    plt.xticks(rotation=45)
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()

    # ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡¨ç¤º
    st.write("**æ—¥åˆ¥æ‰‹å‹•æ¸©åº¦å¤‰æ›´ã‚µãƒãƒªãƒ¼:**")
    st.dataframe(daily_summary_df, use_container_width=True)

def visualize_daily_usage_CHx(df_d):
    """CHxåˆ¥ã®æ—¥åˆ¥ä½¿ç”¨é‡å¯è¦–åŒ–"""
    if df_d.is_empty():
        st.warning("æ—¥åˆ¥ä½¿ç”¨é‡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
        
    # å¯¾è±¡ã® airplug_control_on åˆ—ã‚’å–å¾—
    airplug_on_col = [col for col in df_d.columns if 'airplug_control_on' in col]
    if not airplug_on_col:
        st.warning("airplug_control_onåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
        
    airplug_on_col = airplug_on_col[0]

    # CHx(kW) åˆ—ã‚’æŠ½å‡º
    ch_cols = [col for col in df_d.columns if col.startswith("CH") and "(kW)" in col]
    
    if not ch_cols:
        st.warning("CHx(kW)åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    # ALåˆ¶å¾¡ï¼šairplug_control_on > 0.3ã€å¾“æ¥åˆ¶å¾¡ï¼šairplug_control_on < 0.3
    df_AL = df_d.filter(pl.col(airplug_on_col) > 0.3).select(["measured_at_jst", *ch_cols, "outdoor_temp"])
    df_conv = df_d.filter(pl.col(airplug_on_col) < 0.3).select(["measured_at_jst", *ch_cols, "outdoor_temp"])

    # å„ãƒãƒ£ãƒãƒ«ã® None å€¤ã‚’ 0 ã«ç½®æ›
    for c in ch_cols:
        df_AL = df_AL.with_columns(pl.col(c).fill_null(0))
        df_conv = df_conv.with_columns(pl.col(c).fill_null(0))

    # æ—¥æ™‚ã‚’ matplotlib ç”¨ã®æ•°å€¤ã«å¤‰æ›
    dates_conv = mdates.date2num(df_conv['measured_at_jst'].to_list())
    dates_AL   = mdates.date2num(df_AL['measured_at_jst'].to_list())

    # matplotlib ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚«ãƒ©â€•ã‚µã‚¤ã‚¯ãƒ«ã‚’å–å¾—
    default_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']

    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆä½œæˆï¼ˆå·¦ï¼šå¾“æ¥åˆ¶å¾¡ã€å³ï¼šALåˆ¶å¾¡ï¼‰
    fig, (ax_conv, ax_AL) = plt.subplots(1, 2, figsize=(24, 10))

    # ----- å¾“æ¥åˆ¶å¾¡ã®ã‚¹ã‚¿ãƒƒã‚¯ãƒ‰ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ -----
    bottom_conv = np.zeros(len(df_conv))
    for i, c in enumerate(ch_cols):
        color = default_colors[i % len(default_colors)]
        ax_conv.bar(dates_conv, df_conv[c].to_numpy(), bottom=bottom_conv,
                    label=c, color=color)
        bottom_conv += df_conv[c].to_numpy()

    ax_conv.xaxis_date()
    ax_conv.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
    ax_conv.set_title("å¾“æ¥åˆ¶å¾¡ (AirPlug OFF)")
    ax_conv.set_xlabel("æ—¥æ™‚")
    ax_conv.set_ylabel("é›»æ°—ä½¿ç”¨é‡ (kW)")
    ax_conv.grid(alpha=0.5)
    ax_conv.legend(loc='upper left')

    # ãƒ„ã‚¤ãƒ³è»¸ã§å¤–æ°—æ¸©ã‚’ãƒ—ãƒ­ãƒƒãƒˆï¼ˆé»’ï¼‰
    if 'outdoor_temp' in df_conv.columns:
        ax_conv_twin = ax_conv.twinx()
        ax_conv_twin.plot(dates_conv, df_conv['outdoor_temp'], label='å¤–æ°—æ¸©', color='black')
        ax_conv_twin.set_ylabel("å¤–æ°—æ¸© (Â°C)")

    # ----- ALåˆ¶å¾¡ã®ã‚¹ã‚¿ãƒƒã‚¯ãƒ‰ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ -----
    bottom_AL = np.zeros(len(df_AL))
    for i, c in enumerate(ch_cols):
        color = default_colors[i % len(default_colors)]
        ax_AL.bar(dates_AL, df_AL[c].to_numpy(), bottom=bottom_AL,
                  label=c, color=color)
        bottom_AL += df_AL[c].to_numpy()

    ax_AL.xaxis_date()
    ax_AL.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
    ax_AL.set_title("ALåˆ¶å¾¡ (AirPlug ON)")
    ax_AL.set_xlabel("æ—¥æ™‚")
    ax_AL.set_ylabel("é›»æ°—ä½¿ç”¨é‡ (kW)")
    ax_AL.grid(alpha=0.5)
    ax_AL.legend(loc='upper left')

    # ãƒ„ã‚¤ãƒ³è»¸ã§å¤–æ°—æ¸©ã‚’ãƒ—ãƒ­ãƒƒãƒˆï¼ˆé»’ï¼‰
    if 'outdoor_temp' in df_AL.columns:
        ax_AL_twin = ax_AL.twinx()
        ax_AL_twin.plot(dates_AL, df_AL['outdoor_temp'], label='å¤–æ°—æ¸©', color='black')
        ax_AL_twin.set_ylabel("å¤–æ°—æ¸© (Â°C)")

    plt.tight_layout()
    st.pyplot(fig)
    plt.close()

def visualize_summury(df_h, df_d, df_airid, values, st_h, ed_h):
    """ç·åˆã‚µãƒãƒªãƒ¼ã®å¯è¦–åŒ–"""
    if df_d.is_empty():
        st.warning("ã‚µãƒãƒªãƒ¼ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
        
    day_list = df_d.select(pl.col('measured_at_jst').dt.date().unique()).to_series().to_list()
    zone_num = len(df_airid) if not df_airid.is_empty() else 0

    # æ¸©åº¦ã‚°ãƒ©ãƒ•
    st.subheader("ğŸŒ¡ï¸ æ¸©åº¦ã‚µãƒãƒªãƒ¼")
    fig, ax = plt.subplots(figsize=(12, 6))

    for di in range(len(day_list)):
        df = df_h.filter(pl.col('measured_at_jst').dt.date() == day_list[di])
        
        # ã‚¾ãƒ¼ãƒ³ã®æ¸©åº¦ã‚«ãƒ©ãƒ ã‚’å–å¾—
        zone_cols = [str(zid) for zid in df_airid['zone_id'].unique().to_list()] if not df_airid.is_empty() else []
        valid_zone_cols = [c for c in zone_cols if c in df.columns]
        
        if valid_zone_cols:
            df = df.with_columns(pl.mean_horizontal(valid_zone_cols).alias('mean'))
        else:
            continue

        # AirPlugåˆ¶å¾¡ã®ç¢ºèª
        airplug_cols = [col for col in df_d.columns if 'airplug_control_on' in col]
        if airplug_cols and di < len(df_d):
            airplug_value = df_d.select(airplug_cols[0])[di, 0] if df_d.select(airplug_cols[0]).height > di else None
            color = 'blue' if airplug_value is not None and airplug_value > 0.3 else 'gray'
        else:
            color = 'gray'

        ax.plot(df['measured_at_jst'].dt.hour(), df['mean'], label=str(day_list[di]), color=color)

    ax.set_xticks(np.arange(st_h, ed_h+1, 1))
    ax.set_ylim([22, 28])
    ax.grid(alpha=0.5)
    ax.set_xlabel('æ™‚åˆ»')
    ax.set_ylabel('å¹³å‡æ¸©åº¦ (Â°C)')
    ax.set_title('æ—¥åˆ¥å¹³å‡æ¸©åº¦æ¨ç§»')
    ax.legend()

    st.pyplot(fig)
    plt.close()

    # æŒ‡æ¨™ã®æ£’ã‚°ãƒ©ãƒ•
    if values is not None and len(values) >= 6:
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.bar(['AirPlugæ¸©åº¦èª¤å·®', 'å¾“æ¥åˆ¶å¾¡æ¸©åº¦èª¤å·®'], [values[4], values[5]], color=['blue', 'gray'])
        ax.set_ylabel('æ¸©åº¦èª¤å·® (Â°C)')
        ax.set_title('æ¸©åº¦èª¤å·®æ¯”è¼ƒ')
        st.pyplot(fig)
        plt.close()

    # ã‚¨ãƒãƒ«ã‚®ãƒ¼ä½¿ç”¨é‡ï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰
    if 'Total' in df_d.columns:
        st.subheader("ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚µãƒãƒªãƒ¼")
        visualize_energy_summary(df_h, df_d, st_h, ed_h)
        
        # CHxåˆ¥ã®è¡¨ç¤º
        visualize_daily_usage_CHx(df_d)

        # å¤–æ°—æ¸©vsä½¿ç”¨é‡ã®æ•£å¸ƒå›³
        airplug_on_cols = [col for col in df_d.columns if 'airplug_control_on' in col]
        if airplug_on_cols and 'outdoor_temp' in df_d.columns:
            airplug_on_col = airplug_on_cols[0]
            df_on = df_d.filter(pl.col(airplug_on_col) > 0.3)
            df_off = df_d.filter(pl.col(airplug_on_col) <= 0.3)
            
            fig, ax = plt.subplots(figsize=(10, 6))
            if not df_on.is_empty():
                ax.scatter(df_on['outdoor_temp'], df_on['Total'], label='AirPlug ON', color='blue', alpha=0.7)
            if not df_off.is_empty():
                ax.scatter(df_off['outdoor_temp'], df_off['Total'], label='AirPlug OFF', color='gray', alpha=0.7)
            ax.set_xlabel('å¤–æ°—æ¸© (Â°C)')
            ax.set_ylabel('ã‚¨ãƒãƒ«ã‚®ãƒ¼ä½¿ç”¨é‡ (kWh)')
            ax.set_title('å¤–æ°—æ¸© vs ã‚¨ãƒãƒ«ã‚®ãƒ¼ä½¿ç”¨é‡')
            ax.legend()
            ax.grid(alpha=0.3)
            
            st.pyplot(fig)
            plt.close()

# å¯è¦–åŒ–é–¢æ•°ã‚’è¿½åŠ 

def visualize_temperature_with_mode(df_airplug, df_aircond, df_target, df_airid):
    """ã‚¾ãƒ¼ãƒ³åˆ¥æ¸©åº¦æ¨ç§»ã¨é‹è»¢ãƒ¢ãƒ¼ãƒ‰å¯è¦–åŒ–"""
    if df_airplug.is_empty():
        st.warning("æ¸©åº¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
        
    view_cols = ["set_temperature", "process_temperature"]
    color_list = ['orange', 'green']
    col_labels = ['è¨­å®šæ¸©åº¦', 'å¸è¾¼æ¸©åº¦']  # æ—¥æœ¬èªãƒ©ãƒ™ãƒ«
    
    # ã‚¨ã‚¢ã‚³ãƒ³ã”ã¨ã®æ¸©åº¦æ¨ç§»
    for ai, airid in enumerate(df_airid['id'].to_list()):
        # ãƒ‡ãƒ¼ã‚¿çµåˆ
        df_combine = df_airplug.join(df_aircond, on='measured_at_jst', how='inner') if not df_aircond.is_empty() else df_airplug
        
        # ã‚¾ãƒ¼ãƒ³IDãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        zone_id = str(df_airid['zone_id'][ai])
        if zone_id not in df_combine.columns:
            continue
            
        fig, ax1 = plt.subplots(figsize=(12, 6))
        ax2 = ax1.twinx()
        
        # é‹è»¢çŠ¶æ…‹ãƒã‚¹ã‚¯
        start_stop_col = f'start_stop_{airid}'
        if start_stop_col in df_combine.columns:
            mask = df_combine[start_stop_col] == 2
        else:
            mask = [False] * len(df_combine)
            
        # é‹è»¢ãƒ¢ãƒ¼ãƒ‰
        op_mode_col = f"operation_mode_{airid}"
        if op_mode_col in df_combine.columns:
            op_mode_vals = df_combine[op_mode_col]
            op_mode_colors = [
                'grey' if off else ('cyan' if mode == 1 else ('pink' if mode == 2 else 'white'))
                for off, mode in zip(mask, op_mode_vals)
            ]
        else:
            op_mode_colors = ['blue'] * len(df_combine)
            
        # æ¸©åº¦ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒƒãƒˆ
        ax1.scatter(
            df_combine['measured_at_jst'],
            df_combine[zone_id],
            s=[300 if flag else 100 for flag in mask],
            c=op_mode_colors,
            zorder=1,
            label='é‹è»¢ãƒ¢ãƒ¼ãƒ‰ (ç°:OFF, æ°´è‰²:å†·æˆ¿, ãƒ”ãƒ³ã‚¯:æš–æˆ¿)'
        )
        
        ax1.plot(
            df_combine['measured_at_jst'],
            df_combine[zone_id],
            label='å®¤æ¸©',
            color='blue',
            zorder=2
        )
        
        # è¨­å®šæ¸©åº¦ãƒ»å¸è¾¼æ¸©åº¦
        for k, (col, label) in enumerate(zip(view_cols, col_labels)):
            col_name = f"{col}_{airid}"
            if col_name in df_combine.columns:
                ax1.plot(df_combine['measured_at_jst'], df_combine[col_name], 
                        label=label, color=color_list[k])
                
        # ç›®æ¨™æ¸©åº¦
        if not df_target.is_empty() and 'air_conditioner_id' in df_target.columns:
            df_pick = df_target.filter(pl.col("air_conditioner_id") == airid).sort("measured_at_jst")
            if not df_pick.is_empty() and 'target_temperature' in df_pick.columns:
                ax1.plot(df_pick['measured_at_jst'], df_pick['target_temperature'],
                        label="ç›®æ¨™æ¸©åº¦", color='black', lw=3)
        
        # ã‚°ãƒ©ãƒ•è¨­å®š
        ax1.set_ylim(18, 30)
        ax1.set_xlabel("æ™‚åˆ»")
        ax1.set_ylabel("æ¸©åº¦ (Â°C)")
        ax1.set_title(f"{df_airid['display_name'][ai]} - æ¸©åº¦æ¨ç§»ã¨é‹è»¢ãƒ¢ãƒ¼ãƒ‰")
        ax1.legend(loc='upper left', bbox_to_anchor=(0, 1))
        ax1.grid(True, alpha=0.3)
        
        st.pyplot(fig)

def visualize_summary(df_h, df_d, values, st_h, ed_h, df_airid):
    """ç·åˆã‚µãƒãƒªãƒ¼å¯è¦–åŒ– - ã‚°ãƒ©ãƒ•ç”»åƒè¾æ›¸ã‚’è¿”ã™ãƒãƒ¼ã‚¸ãƒ§ãƒ³"""
    graph_images = {}
    
    if df_d.is_empty() or df_h.is_empty():
        st.warning("ã‚µãƒãƒªãƒ¼è¡¨ç¤ºç”¨ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return graph_images
        
    # --- æ¸©åº¦ã‚°ãƒ©ãƒ• ---
    fig1, ax1 = plt.subplots(figsize=(12, 5))
    day_list = df_d.select(pl.col('measured_at_jst').dt.date()).unique().to_series().to_list()
    
    zone_cols = [str(zid) for zid in df_airid['zone_id'].unique().to_list()]
    valid_zone_cols = [c for c in zone_cols if c in df_h.columns]
    
    for di, day in enumerate(day_list):
        df_day = df_h.filter(pl.col('measured_at_jst').dt.date() == day)
        if df_day.is_empty() or not valid_zone_cols:
            continue
            
        # ã‚¾ãƒ¼ãƒ³å¹³å‡æ¸©åº¦
        df_day = df_day.with_columns(pl.mean_horizontal(valid_zone_cols).alias('mean'))
        
        # AirPlugåˆ¶å¾¡ã®åˆ¤å®š
        airplug_on_col = next((col for col in df_d.columns if 'airplug_control_on' in col), None)
        if airplug_on_col and df_d.filter(pl.col('measured_at_jst').dt.date() == day)[airplug_on_col].mean() > 0.3:
            color = 'blue'
        else:
            color = 'gray'
            
        ax1.plot(df_day['measured_at_jst'].dt.hour(), df_day['mean'], 
               label=str(day), color=color)
    
    ax1.set_title("æ—¥åˆ¥ å¹³å‡æ¸©åº¦æ¨ç§» (é’:ALåˆ¶å¾¡ / ç°:å¾“æ¥åˆ¶å¾¡)")
    ax1.set_xlabel("æ™‚é–“ (æ™‚)")
    ax1.set_ylabel("å¹³å‡æ¸©åº¦ (â„ƒ)")
    ax1.grid(alpha=0.5)
    
    # ã‚°ãƒ©ãƒ•ã‚’ç”»åƒãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿å­˜
    buf = io.BytesIO()
    fig1.savefig(buf, format='png', bbox_inches='tight')
    buf.seek(0)
    graph_images['temperature_summary'] = PIL.Image.open(buf)
    
    # Streamlitã«ã‚‚è¡¨ç¤º
    st.subheader("æ¸©åº¦æ¨ç§»ã‚µãƒãƒªãƒ¼")
    st.pyplot(fig1)
    plt.close(fig1)
    
    # --- é›»åŠ›æ¶ˆè²»ã‚°ãƒ©ãƒ• ---
    airplug_on_col = next((col for col in df_d.columns if 'airplug_control_on' in col), None)
    if airplug_on_col and 'outdoor_temp' in df_d.columns and 'Total' in df_d.columns:
        fig2, ax2 = plt.subplots(figsize=(12, 5))
        df_on = df_d.filter(pl.col(airplug_on_col) > 0.3)
        df_off = df_d.filter(pl.col(airplug_on_col) <= 0.3)

        if not df_on.is_empty():
            ax2.scatter(df_on['outdoor_temp'], df_on['Total'], label='ALåˆ¶å¾¡', color='blue')
        if not df_off.is_empty():
            ax2.scatter(df_off['outdoor_temp'], df_off['Total'], label='å¾“æ¥åˆ¶å¾¡', color='gray')
        
        ax2.set_title("å¤–æ°—æ¸© vs æ¶ˆè²»é›»åŠ› (Total)")
        ax2.set_xlabel("å¤–æ°—æ¸© (â„ƒ)")
        ax2.set_ylabel("æ—¥åˆ¥ç·æ¶ˆè²»é›»åŠ› (kWh)")
        ax2.legend()
        ax2.grid(alpha=0.5)

        # ã‚°ãƒ©ãƒ•ã‚’ç”»åƒãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿å­˜
        buf = io.BytesIO()
        fig2.savefig(buf, format='png', bbox_inches='tight')
        buf.seek(0)
        graph_images['energy_scatter'] = PIL.Image.open(buf)
        
        # Streamlitã«ã‚‚è¡¨ç¤º
        st.subheader("å¤–æ°—æ¸© vs æ¶ˆè²»é›»åŠ›")
        st.pyplot(fig2)
        plt.close(fig2)
    
    return graph_images

def visualize_energy_summary(df_d, df_h, st_h, ed_h):
    """ã‚¨ãƒãƒ«ã‚®ãƒ¼åˆ†æã‚µãƒãƒªãƒ¼"""
    if df_d.is_empty() or 'Total' not in df_d.columns:
        st.info("ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
        
    # æ—¥åˆ¥ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»
    st.subheader("æ—¥åˆ¥ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»é‡")
    
    airplug_on_col = next((col for col in df_d.columns if 'airplug_control_on' in col), None)
    
    if airplug_on_col:
        df_on = df_d.filter(pl.col(airplug_on_col) > 0.3)
        df_off = df_d.filter(pl.col(airplug_on_col) <= 0.3)
        
        fig, ax1 = plt.subplots(figsize=(12, 6))
        
        # æ£’ã‚°ãƒ©ãƒ•
        if not df_on.is_empty():
            ax1.bar(df_on['measured_at_jst'], df_on['Total'], 
                   label='AirPlugåˆ¶å¾¡', color='blue', alpha=0.7)
        if not df_off.is_empty():
            ax1.bar(df_off['measured_at_jst'], df_off['Total'], 
                   label='å¾“æ¥åˆ¶å¾¡', color='gray', alpha=0.7)
        
        ax1.set_xlabel("æ—¥ä»˜")
        ax1.set_ylabel("é›»åŠ›æ¶ˆè²»é‡ (kWh)")
        ax1.set_title("æ—¥åˆ¥é›»åŠ›æ¶ˆè²»é‡")
        
        # å¤–æ°—æ¸©
        if 'outdoor_temp' in df_d.columns:
            ax2 = ax1.twinx()
            ax2.plot(df_d['measured_at_jst'], df_d['outdoor_temp'], 
                    label='å¤–æ°—æ¸©', color='red', linewidth=2)
            ax2.set_ylabel("å¤–æ°—æ¸© (Â°C)")
            
        ax1.legend(loc='upper left')
        st.pyplot(fig)
        
        # çµ±è¨ˆæƒ…å ±
        col1, col2 = st.columns(2)
        with col1:
            if not df_on.is_empty():
                st.metric("AirPlugåˆ¶å¾¡ å¹³å‡æ¶ˆè²»é‡", 
                         f"{df_on['Total'].mean():.2f} kWh" if df_on['Total'].mean() is not None else "N/A")
        with col2:
            if not df_off.is_empty():
                st.metric("å¾“æ¥åˆ¶å¾¡ å¹³å‡æ¶ˆè²»é‡", 
                         f"{df_off['Total'].mean():.2f} kWh" if df_off['Total'].mean() is not None else "N/A")

def visualize_daily_usage_CHx(df_d):
    """CHxåˆ¥ã‚¹ã‚¿ãƒƒã‚¯ãƒ‰ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ"""
    if df_d.is_empty():
        return
        
    ch_cols = [col for col in df_d.columns if col.startswith("CH") and "(kW)" in col]
    if not ch_cols:
        st.info("ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
        
    st.subheader("ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥é›»åŠ›æ¶ˆè²»é‡")
    
    airplug_on_col = next((col for col in df_d.columns if 'airplug_control_on' in col), None)
    
    if airplug_on_col:
        df_AL = df_d.filter(pl.col(airplug_on_col) > 0.3)
        df_conv = df_d.filter(pl.col(airplug_on_col) <= 0.3)
        
        fig, (ax_conv, ax_AL) = plt.subplots(1, 2, figsize=(16, 6))
        
        # å¾“æ¥åˆ¶å¾¡
        if not df_conv.is_empty():
            bottom_conv = np.zeros(len(df_conv))
            for i, c in enumerate(ch_cols):
                values = df_conv[c].fill_null(0).to_numpy()
                ax_conv.bar(range(len(df_conv)), values, bottom=bottom_conv,
                           label=c)
                bottom_conv += values
            
            ax_conv.set_title("å¾“æ¥åˆ¶å¾¡")
            ax_conv.set_xlabel("æ—¥æ•°")
            ax_conv.set_ylabel("é›»åŠ›æ¶ˆè²»é‡ (kW)")
            ax_conv.legend()
            
        # AirPlugåˆ¶å¾¡
        if not df_AL.is_empty():
            bottom_AL = np.zeros(len(df_AL))
            for i, c in enumerate(ch_cols):
                values = df_AL[c].fill_null(0).to_numpy()
                ax_AL.bar(range(len(df_AL)), values, bottom=bottom_AL,
                         label=c)
                bottom_AL += values
            
            ax_AL.set_title("AirPlugåˆ¶å¾¡")
            ax_AL.set_xlabel("æ—¥æ•°")
            ax_AL.set_ylabel("é›»åŠ›æ¶ˆè²»é‡ (kW)")
            ax_AL.legend()
        
        plt.tight_layout()
        st.pyplot(fig)

def visualize_outdoor_correlation(df_d):
    """å¤–æ°—æ¸©ã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ã®ç›¸é–¢"""
    if df_d.is_empty() or 'outdoor_temp' not in df_d.columns or 'Total' not in df_d.columns:
        return
        
    st.subheader("å¤–æ°—æ¸©ã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ã®ç›¸é–¢")
    
    airplug_on_col = next((col for col in df_d.columns if 'airplug_control_on' in col), None)
    
    if airplug_on_col:
        df_on = df_d.filter(pl.col(airplug_on_col) > 0.3)
        df_off = df_d.filter(pl.col(airplug_on_col) <= 0.3)
        
        fig, ax = plt.subplots(figsize=(8, 6))
        
        if not df_on.is_empty():
            ax.scatter(df_on['outdoor_temp'], df_on['Total'], 
                      label='AirPlugåˆ¶å¾¡', color='blue', alpha=0.7)
                      
        if not df_off.is_empty():
            ax.scatter(df_off['outdoor_temp'], df_off['Total'], 
                      label='å¾“æ¥åˆ¶å¾¡', color='gray', alpha=0.7)
        
        ax.set_xlabel("å¤–æ°—æ¸© (Â°C)")
        ax.set_ylabel("é›»åŠ›æ¶ˆè²»é‡ (kWh)")
        ax.set_title("å¤–æ°—æ¸© vs é›»åŠ›æ¶ˆè²»é‡")
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        st.pyplot(fig)

def visualize_remote_control_streamlit(df_all, st_dt, ed_dt):
    """ãƒªãƒ¢ã‚³ãƒ³æ“ä½œå¯è¦–åŒ–ï¼ˆStreamlitç‰ˆï¼‰"""
    if df_all.is_empty():
        st.info("ãƒªãƒ¢ã‚³ãƒ³æ“ä½œãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
        
    st.subheader("ãƒªãƒ¢ã‚³ãƒ³æ‰‹å‹•æ“ä½œåˆ†æ")
    
    # Pandas DataFrameã«å¤‰æ›
    temp_df = df_all.to_pandas()
    temp_df['measured_at_jst'] = pd.to_datetime(temp_df['measured_at_jst'])
    set_temperature_columns = [col for col in df_all.columns if col.startswith("set_temperature_")]
    
    if not set_temperature_columns:
        st.info("è¨­å®šæ¸©åº¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # æ—¥åˆ¥ã®æ‰‹å‹•å¤‰æ›´ã‚’é›†è¨ˆ
    date_range = pd.date_range(start=st_dt, end=ed_dt, freq='D')
    daily_summary = []
    
    for date in date_range:
        date_data = temp_df[temp_df['measured_at_jst'].dt.date == date.date()]
        total_up = 0
        total_down = 0
        
        if not date_data.empty:
            for room in set_temperature_columns:
                if room in date_data.columns:
                    temp_diff = date_data[room].diff()
                    # 0.5åº¦å˜ä½ã®æ‰‹å‹•å¤‰æ›´ã‚’æ¤œå‡º
                    total_up += ((temp_diff > 0) & (temp_diff % 0.5 == 0)).sum()
                    total_down += ((temp_diff < 0) & (temp_diff % 0.5 == 0)).sum()
        
        daily_summary.append({
            'æ—¥ä»˜': date,
            'æ¸©åº¦ä¸Šã’': int(total_up),
            'æ¸©åº¦ä¸‹ã’': int(total_down),
            'ç·å¤‰æ›´å›æ•°': int(total_up + total_down)
        })
    
    daily_summary_df = pd.DataFrame(daily_summary)
    
    # æ—¥åˆ¥å¤‰å‹•ã‚°ãƒ©ãƒ•
    if not daily_summary_df.empty:
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.plot(daily_summary_df['æ—¥ä»˜'], daily_summary_df['æ¸©åº¦ä¸Šã’'], 
               marker='o', color='red', label='æ¸©åº¦ä¸Šã’ (+0.5Â°C)')
        ax.plot(daily_summary_df['æ—¥ä»˜'], daily_summary_df['æ¸©åº¦ä¸‹ã’'], 
               marker='o', color='blue', label='æ¸©åº¦ä¸‹ã’ (-0.5Â°C)')
        ax.set_xlabel('æ—¥ä»˜')
        ax.set_ylabel('æ“ä½œå›æ•°')
        ax.set_title('æ—¥åˆ¥ãƒªãƒ¢ã‚³ãƒ³æ‰‹å‹•æ“ä½œå›æ•°')
        ax.legend()
        ax.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        
        st.pyplot(fig)
        
        # ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«
        st.dataframe(daily_summary_df)

def visualize_button_heatmap(df_h, df_airid, st_h, ed_h):
    """ãƒœã‚¿ãƒ³æ“ä½œãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—"""
    if df_h.is_empty():
        st.info("ãƒœã‚¿ãƒ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
        
    bt_cols = [col for col in df_h.columns if col.startswith('bt_')]
    if not bt_cols:
        st.info("ãƒœã‚¿ãƒ³æ“ä½œãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
        
    st.subheader("ãƒœã‚¿ãƒ³æ“ä½œãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
    
    # æ—¥åˆ¥ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
    visualize_date = df_h.with_columns(pl.col('measured_at_jst').dt.date()).select('measured_at_jst').unique()
    
    for di, date in enumerate(visualize_date['measured_at_jst'].to_list()):
        df = df_h.filter(pl.col('measured_at_jst').dt.date() == date)
        df_bt = df.select(['measured_at_jst'] + bt_cols)
        
        if df_bt.shape[0] > 0:
            # ãƒ‡ãƒ¼ã‚¿ã‚’é…åˆ—ã«å¤‰æ›
            bt_data = df_bt.drop('measured_at_jst').to_numpy().T
            
            fig, ax = plt.subplots(figsize=(12, 6))
            im = ax.imshow(bt_data, extent=(st_h, ed_h+1, len(bt_cols), 0), 
                          cmap='seismic_r', aspect='auto')
            
            ax.set_xlabel('æ™‚åˆ»')
            ax.set_ylabel('ã‚¨ã‚¢ã‚³ãƒ³')
            ax.set_title(f'ãƒœã‚¿ãƒ³æ“ä½œãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— - {date}')
            ax.set_yticks(range(len(bt_cols)))
            
            # ã‚¨ã‚¢ã‚³ãƒ³åã‚’å–å¾—ã—ã¦ãƒ©ãƒ™ãƒ«ã«ä½¿ç”¨
            bt_labels = []
            for col in bt_cols:
                ac_id = col.replace('bt_', '')
                # df_airidã‹ã‚‰è¡¨ç¤ºåã‚’å–å¾—
                display_name = df_airid.filter(pl.col('id') == ac_id)['display_name']
                if not display_name.is_empty():
                    bt_labels.append(display_name[0])
                else:
                    bt_labels.append(ac_id)
            
            ax.set_yticklabels(bt_labels)
            
            cbar = plt.colorbar(im, ax=ax)
            cbar.set_label('æ“ä½œå›æ•°ï¼ˆï¼‹ï¼šæš‘ã„ã€âˆ’ï¼šå¯’ã„ï¼‰')
            
            st.pyplot(fig)

# ãƒ¡ã‚¤ãƒ³ã®ã‚¿ãƒ–æ§‹æˆã‚’æ›´æ–°
def display_analysis_results(results, params):
    """åˆ†æçµæœã®è¡¨ç¤º"""
    st.markdown("---")
    st.header("åˆ†æçµæœ")
    
    # ä¸»è¦æŒ‡æ¨™è¡¨ç¤º
    display_key_metrics(results['values'])
    
    # ã‚¿ãƒ–ã§è©³ç´°è¡¨ç¤º
    tabs = st.tabs([
        "æ¸©åº¦åˆ†æ", 
        "ã‚¨ãƒãƒ«ã‚®ãƒ¼åˆ†æ", 
        "ãƒªãƒ¢ã‚³ãƒ³ãƒ»ãƒœã‚¿ãƒ³æ“ä½œ", 
        "ç·åˆã‚µãƒãƒªãƒ¼",
        "LLMåˆ†æãƒ¬ãƒãƒ¼ãƒˆ",
        "ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
    ])
    
    with tabs[0]:  # æ¸©åº¦åˆ†æ
        st.subheader("æ¸©åº¦åˆ†æ")
        
        # ã‚¾ãƒ¼ãƒ³åˆ¥æ¸©åº¦æ¨ç§»ã¨é‹è»¢ãƒ¢ãƒ¼ãƒ‰
        if 'df_airplug' in results and 'df_aircond' in results:
            visualize_temperature_with_mode(
                results.get('df_airplug', pl.DataFrame()),
                results.get('df_aircond', pl.DataFrame()),
                results.get('df_target', pl.DataFrame()),
                results['df_airid']
            )
        else:
            # ã‚·ãƒ³ãƒ—ãƒ«ãªæ¸©åº¦æ¨ç§»
            visualize_temperature_data(results['df_combine'], results['df_airid'], 
                                     params['st_h'], params['ed_h'])
    
    with tabs[1]:  # ã‚¨ãƒãƒ«ã‚®ãƒ¼åˆ†æ
        st.subheader("ã‚¨ãƒãƒ«ã‚®ãƒ¼åˆ†æ")
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚µãƒãƒªãƒ¼
        visualize_energy_summary(results['df_d'], results['df_h'], 
                               params['st_h'], params['ed_h'])
        
        # CHxåˆ¥åˆ†æ
        visualize_daily_usage_CHx(results['df_d'])
        
        # å¤–æ°—æ¸©ç›¸é–¢
        visualize_outdoor_correlation(results['df_d'])
    
    with tabs[2]:  # ãƒªãƒ¢ã‚³ãƒ³ãƒ»ãƒœã‚¿ãƒ³æ“ä½œ
        st.subheader("æ“ä½œåˆ†æ")
        
        # ãƒªãƒ¢ã‚³ãƒ³æ“ä½œ
        visualize_remote_control_streamlit(results['df_all'], 
                                         params['st_dt_ymdhms'], 
                                         params['ed_dt_ymdhms'])
        
        # ãƒœã‚¿ãƒ³æ“ä½œãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        visualize_button_heatmap(results['df_h'], results['df_airid'],
                               params['st_h'], params['ed_h'])
        
        # ãƒœã‚¿ãƒ³æ“ä½œçµ±è¨ˆ
        if not results['df_d'].is_empty():
            calc_button_stats(results['df_all'], results['df_d'], results['df_airid'])
    
    with tabs[3]:  # ç·åˆã‚µãƒãƒªãƒ¼
        st.subheader("ç·åˆã‚µãƒãƒªãƒ¼")
        
        # æ¸©åº¦ã‚µãƒãƒªãƒ¼
        visualize_summary(results['df_h'], results['df_d'], results['values'],
                        params['st_h'], params['ed_h'], results['df_airid'])
        
        # æŒ‡æ¨™ã‚µãƒãƒªãƒ¼
        display_metrics_summary(results['values'])
    
    with tabs[4]:  # LLMåˆ†æãƒ¬ãƒãƒ¼ãƒˆ
        st.subheader("ğŸ¤– LLMåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        
        if not GEMINI_AVAILABLE:
            st.error("Gemini APIãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚APIã‚­ãƒ¼ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        else:
            st.info("ã“ã®ã‚¿ãƒ–ã§ã¯ã€AIï¼ˆGeminiï¼‰ã‚’ä½¿ç”¨ã—ã¦ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µã‚¯ã‚»ã‚¹å‘ã‘ã®åŒ…æ‹¬çš„ãªåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
            
            # LLMãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒœã‚¿ãƒ³
            if st.button("ğŸ“Š LLMãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ", type="primary", key="generate_llm_report"):
                # ã‚µãƒãƒªãƒ¼ã‚°ãƒ©ãƒ•ã‹ã‚‰ã‚°ãƒ©ãƒ•ç”»åƒã‚’å–å¾—
                graph_images = visualize_summary(
                    results.get('df_h', pl.DataFrame()),
                    results.get('df_d', pl.DataFrame()),
                    results.get('values', []),
                    params.get('st_h', 8),
                    params.get('ed_h', 20),
                    results.get('df_airid', pl.DataFrame())
                )
                
                # ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
                report_data = {
                    'period_start': params.get('st_dt_ymdhms', '').strftime('%Y-%m-%d') if params.get('st_dt_ymdhms') else 'N/A',
                    'period_end': params.get('ed_dt_ymdhms', '').strftime('%Y-%m-%d') if params.get('ed_dt_ymdhms') else 'N/A',
                    'floor_name': params.get('floor_name', 'N/A'),
                    'temp_error_conv': f"{results['values'][5]:.2f}" if len(results.get('values', [])) > 5 else 'N/A',
                    'temp_error_al': f"{results['values'][4]:.2f}" if len(results.get('values', [])) > 4 else 'N/A',
                    'energy_conv_kwh': 'N/A',  # ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã«è¨ˆç®—
                    'energy_al_kwh': 'N/A',    # ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã«è¨ˆç®—
                    'control_efficiency_rate': 'N/A',  # åˆ¶å¾¡åŠ¹ç‡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã«è¨ˆç®—
                    'manual_ops_conv': 'N/A',  # æ‰‹å‹•æ“ä½œãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã«è¨ˆç®—
                    'manual_ops_al': 'N/A'     # æ‰‹å‹•æ“ä½œãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã«è¨ˆç®—
                }
                
                # LLMãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
                with st.spinner("AIåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­..."):
                    report_text = generate_customer_success_report(report_data, graph_images)
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                st.session_state.llm_report = report_text
                st.session_state.llm_report_data = report_data
                
                st.success("âœ… LLMåˆ†æãƒ¬ãƒãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼")
            
            # ç”Ÿæˆæ¸ˆã¿ãƒ¬ãƒãƒ¼ãƒˆãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
            if st.session_state.llm_report:
                st.markdown("### ğŸ“‹ ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µã‚¯ã‚»ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
                st.markdown(st.session_state.llm_report)
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                col1, col2 = st.columns(2)
                
                with col1:
                    st.download_button(
                        label="ğŸ“¥ ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (.md)",
                        data=st.session_state.llm_report,
                        file_name=f"customer_success_report_{params.get('floor_name', 'floor')}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                        mime="text/markdown",
                        key="llm_report_download_md"
                    )
                
                with col2:
                    # PDFå¤‰æ›ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    pdf_data = convert_markdown_to_pdf(
                        st.session_state.llm_report, 
                        f"customer_success_report_{params.get('floor_name', 'floor')}"
                    )
                    
                    if pdf_data:
                        st.download_button(
                            label="ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (.pdf)",
                            data=pdf_data,
                            file_name=f"customer_success_report_{params.get('floor_name', 'floor')}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                            mime="application/pdf",
                            key="llm_report_download_pdf"
                        )
                
                # ãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ãƒœã‚¿ãƒ³
                if st.button("ğŸ—‘ï¸ ãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢", key="clear_llm_report"):
                    st.session_state.llm_report = None
                    st.session_state.llm_report_data = None
                    st.rerun()
    
    with tabs[5]:  # ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        download_section(results, params)

def calc_button_stats(df_all, df_d, df_airid):
    """ãƒœã‚¿ãƒ³æ“ä½œçµ±è¨ˆ"""
    st.subheader("ãƒœã‚¿ãƒ³æ“ä½œçµ±è¨ˆ")
    
    day_list = df_d.select(pl.col('measured_at_jst').dt.date().unique()).to_series().to_list()
    df_df = df_all.select(['measured_at_jst'] + 
                         [col for col in df_all.columns if col.startswith('bt_')])
    
    stats = []
    for day in day_list:
        df = df_df.filter(pl.col('measured_at_jst').dt.date() == day)
        
        if not df.is_empty():
            bt_cols = [col for col in df.columns if col.startswith('bt_')]
            if bt_cols:
                bt_array = df.select(bt_cols).to_numpy()
                
                btp = bt_array[bt_array > 0]
                btm = bt_array[bt_array < 0]
                
                stats.append({
                    'æ—¥ä»˜': day,
                    'æš‘ã„ãƒœã‚¿ãƒ³å›æ•°': np.sum(btp) if len(btp) > 0 else 0,
                    'å¯’ã„ãƒœã‚¿ãƒ³å›æ•°': np.abs(np.sum(btm)) if len(btm) > 0 else 0,
                    'æš‘ã„ãƒœã‚¿ãƒ³é »åº¦': len(btp),
                    'å¯’ã„ãƒœã‚¿ãƒ³é »åº¦': len(btm)
                })
    
    if stats:
        stats_df = pd.DataFrame(stats)
        st.dataframe(stats_df)

def display_metrics_summary(values):
    """æŒ‡æ¨™ã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
    if values is None or len(values) < 11:
        return
        
    st.subheader("è©³ç´°æŒ‡æ¨™")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**AirPlugåˆ¶å¾¡æ™‚**")
        st.metric("å¹³å‡æ¸©åº¦", f"{values[0]:.2f}Â°C" if not np.isnan(values[0]) else "N/A")
        st.metric("æ¸©åº¦æ¨™æº–åå·®", f"{values[2]:.2f}" if not np.isnan(values[2]) else "N/A")
        st.metric("ç›®æ¨™æ¸©åº¦èª¤å·®", f"{values[4]:.2f}Â°C" if not np.isnan(values[4]) else "N/A")
        st.metric("è¨­å®šæ¸©åº¦å¤‰æ›´å›æ•°", f"{int(values[6])}" if not np.isnan(values[6]) else "N/A")
        st.metric("ç¨¼åƒç‡", f"{values[8]:.1f}%" if not np.isnan(values[8]) else "N/A")
        
    with col2:
        st.write("**å¾“æ¥åˆ¶å¾¡æ™‚**")
        st.metric("å¹³å‡æ¸©åº¦", f"{values[1]:.2f}Â°C" if not np.isnan(values[1]) else "N/A")
        st.metric("æ¸©åº¦æ¨™æº–åå·®", f"{values[3]:.2f}" if not np.isnan(values[3]) else "N/A")
        st.metric("ç›®æ¨™æ¸©åº¦èª¤å·®", f"{values[5]:.2f}Â°C" if not np.isnan(values[5]) else "N/A")
        st.metric("è¨­å®šæ¸©åº¦å¤‰æ›´å›æ•°", f"{int(values[7])}" if not np.isnan(values[7]) else "N/A")
        st.metric("ç¨¼åƒç‡", f"{values[9]:.1f}%" if not np.isnan(values[9]) else "N/A")
    
    st.metric("ãƒ‡ãƒ¼ã‚¿æ¬ æç‡", f"{values[10]:.1f}%" if not np.isnan(values[10]) else "N/A")

def download_section(results, params):
    """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if not results['df_all'].is_empty():
            csv_all = results['df_all'].to_pandas().to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="â†“ åˆ†ãƒ‡ãƒ¼ã‚¿ (CSV)",
                data=csv_all,
                file_name=f"df_min_floor{params['floor_name']}_start_{params['st_dt_ymdhms'].strftime('%Y%m%d')}_{params['sys_kind']}_{params['energy_kind']}.csv",
                mime="text/csv"
            )
    
    with col2:
        if not results['df_h'].is_empty():
            csv_h = results['df_h'].to_pandas().to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="â†“ æ™‚é–“ãƒ‡ãƒ¼ã‚¿ (CSV)",
                data=csv_h,
                file_name=f"df_hour_floor{params['floor_name']}_start_{params['st_dt_ymdhms'].strftime('%Y%m%d')}_{params['sys_kind']}_{params['energy_kind']}.csv",
                mime="text/csv"
            )
    
    with col3:
        if not results['df_d'].is_empty():
            csv_d = results['df_d'].to_pandas().to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="â†“ æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ (CSV)",
                data=csv_d,
                file_name=f"df_day_floor{params['floor_name']}_start_{params['st_dt_ymdhms'].strftime('%Y%m%d')}_{params['sys_kind']}_{params['energy_kind']}.csv",
                mime="text/csv"
            )

def load_energy_csv(params):
    """ã‚¨ãƒãƒ«ã‚®ãƒ¼CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
    st.sidebar.subheader("ğŸ“ ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_file = st.sidebar.file_uploader(
        "ã‚¨ãƒãƒ«ã‚®ãƒ¼CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", 
        type=['csv'],
        help="master.csv ã¾ãŸã¯ energy.csv ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
    )
    
    if uploaded_file is not None:
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        try:
            if params['energy_format_type'] == 'master':
                df = pl.read_csv(uploaded_file, null_values=["-"])[:, 2:]
            elif params['energy_format_type'] == 'hioki':
                df = pl.read_csv(uploaded_file, skip_rows=26, null_values=["-"])[:, 3:]
            else:
                df = pl.read_csv(uploaded_file, null_values=["-"])
            
            st.sidebar.success(f"âœ… {uploaded_file.name} ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            return df, True
        except Exception as e:
            st.sidebar.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return pl.DataFrame(), False
    else:
        return pl.DataFrame(), False

# calc_energyé–¢æ•°ã‚’ä¿®æ­£
def calc_energy_with_csv(st_h, ed_h, df_combine, energy_df=None):
    """ã‚¨ãƒãƒ«ã‚®ãƒ¼è¨ˆç®—ï¼ˆCSVãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œç‰ˆï¼‰"""
    try:
        if energy_df is not None and not energy_df.is_empty():
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
            ch_num = energy_df.shape[1] - 1
            
            # æ—¥æ™‚åˆ—ã®æ•´å½¢
            df_raw = energy_df.drop_nulls()
            df_raw = df_raw.with_columns(
                pl.col("DateTime").str.to_datetime("%Y-%m-%d %H:%M:%S").alias('measured_at_jst')
            ).drop('DateTime')
            
            # æŒ‡å®šæ™‚é–“å¸¯ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            df = df_raw.filter(
                (pl.col('measured_at_jst').dt.hour() >= st_h) &
                (pl.col('measured_at_jst').dt.hour() <= ed_h)
            )
            
            # Totalåˆ—è¿½åŠ 
            energy_cols = [col for col in df.columns if col != 'measured_at_jst']
            df = df.with_columns(pl.sum_horizontal(energy_cols).alias('Total'))
            
            # df_combineã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼æƒ…å ±ã‚’çµåˆ
            df_ecombine = df_combine.join(df.select(['measured_at_jst', 'Total']), 
                                         on='measured_at_jst', how='left')
            
            # æ™‚é–“åˆ¥ãƒ»æ—¥åˆ¥é›†è¨ˆ
            df_h = df.group_by_dynamic("measured_at_jst", every="1h").agg(pl.col("*").mean())
            df_d = df_h.group_by_dynamic("measured_at_jst", every="1d").agg(pl.col("*").sum())
            
            # AirPlugåˆ¶å¾¡ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
            airplug_cols = [col for col in df_ecombine.columns if 'airplug_control_on' in col]
            if airplug_cols:
                column = airplug_cols[0]
                df_h = df_h.join(df_ecombine.group_by_dynamic("measured_at_jst", every="1h")
                                .agg(pl.col(column).mean()).select(['measured_at_jst', column]), 
                                on='measured_at_jst', how='left')
                df_d = df_d.join(df_ecombine.group_by_dynamic("measured_at_jst", every="1d")
                                .agg(pl.col(column).mean()).select(['measured_at_jst', column]), 
                                on='measured_at_jst', how='left')
            
            return df_ecombine, df_h, df_d
            
        else:
            # CSVãŒãªã„å ´åˆã®ãƒ€ãƒŸãƒ¼å‡¦ç†ï¼ˆæ—¢å­˜ã®å‡¦ç†ï¼‰
            return calc_energy(st_h, ed_h, df_combine)
            
    except Exception as e:
        st.error(f"ã‚¨ãƒãƒ«ã‚®ãƒ¼è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        return calc_energy(st_h, ed_h, df_combine)

def setup_google_drive():
    """Google Drive APIè¨­å®š"""
    # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®èªè¨¼æƒ…å ±ï¼ˆJSONãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ãŒå¿…è¦
    # Streamlit Secretsã«ä¿å­˜ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨
    
    try:
        # Streamlit Secretsã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—
        creds_dict = st.secrets["google_drive"]
        creds = service_account.Credentials.from_service_account_info(
            creds_dict,
            scopes=['https://www.googleapis.com/auth/drive.readonly']
        )
        
        service = build('drive', 'v3', credentials=creds)
        return service
    except Exception as e:
        st.error(f"Google Driveèªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def download_from_drive(service, file_id):
    """Google Driveã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«IDã‚’æŒ‡å®šã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        request = service.files().get_media(fileId=file_id)
        file_data = io.BytesIO()
        downloader = MediaIoBaseDownload(file_data, request)
        
        done = False
        while not done:
            status, done = downloader.next_chunk()
            
        file_data.seek(0)
        return file_data
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def load_energy_from_gdrive(customer_dir, add_dir, energy_kind='master'):
    """Google Driveã‹ã‚‰ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    service = setup_google_drive()
    if service is None:
        return pl.DataFrame(), False
    
    # ãƒ•ã‚¡ã‚¤ãƒ«IDã®ç®¡ç†ï¼ˆä¾‹ï¼šè¾æ›¸ã§ç®¡ç†ï¼‰
    file_mapping = {
        '/é‡æ‘ä¸å‹•ç”£/Data/master.csv': 'YOUR_FILE_ID_HERE',
        # ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’è¿½åŠ 
    }
    
    file_path = f"{customer_dir}{add_dir}/{energy_kind}.csv"
    file_id = file_mapping.get(file_path)
    
    if file_id:
        file_data = download_from_drive(service, file_id)
        if file_data:
            df = pl.read_csv(file_data, null_values=["-"])
            return df, True
    
    return pl.DataFrame(), False

def generate_customer_success_report(report_data, graph_images):
    """
    é›†ç´„ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¨ã‚°ãƒ©ãƒ•ç”»åƒã‹ã‚‰ã€ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µã‚¯ã‚»ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    if not GEMINI_AVAILABLE:
        return "Gemini APIãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚APIã‚­ãƒ¼ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
    
    # Gemini Pro Visionãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    model = genai.GenerativeModel('gemini-2.0-flash')

    # LLMã¸ã®æŒ‡ç¤ºï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ã‚’ä½œæˆ
    prompt_parts = [
        "ã‚ãªãŸã¯AIç©ºèª¿åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ã€ŒAirPlugã€ã®ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µã‚¯ã‚»ã‚¹æ‹…å½“è€…ã§ã™ã€‚",
        "ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã¨ã‚°ãƒ©ãƒ•ã‚’ç·åˆçš„ã«åˆ†æã—ã€é¡§å®¢å‘ã‘ã®å°å…¥åŠ¹æœãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚",
        "ãƒ¬ãƒãƒ¼ãƒˆã¯ã€ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ã€‘ã€åˆ†æçµæœè©³ç´°ã€‘ã€ç·åˆè©•ä¾¡ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã€‘ã®3éƒ¨æ§‹æˆã¨ã—ã¾ã™ã€‚",
        "åˆ†æã®éš›ã¯ã€ä»¥ä¸‹ã®4ã¤ã®æŒ‡æ¨™ã‚’å¿…ãšå®šé‡è©•ä¾¡å®šé‡ã«å«ã‚ã¦ãã ã•ã„ï¼š",
        "1. æ¸©åº¦å®‰å®šæ€§ï¼šç›®æ¨™æ¸©åº¦ã¨ã®èª¤å·®ãŒå°ã•ã„ã»ã©è‰¯ã„ã€‚",
        "2. çœã‚¨ãƒåŠ¹æœï¼šé›»åŠ›æ¶ˆè²»é‡ãŒå°‘ãªã„ã»ã©è‰¯ã„ã€‚",
        "3. åˆ¶å¾¡åŠ¹ç‡ï¼šALåˆ¶å¾¡ã®æˆåŠŸç‡ãŒé«˜ã„ã»ã©è‰¯ã„ã€‚",
        "4. å¿«é©æ€§å‘ä¸Šï¼šæ‰‹å‹•ã§ã®æ¸©åº¦æ“ä½œå›æ•°ãŒå°‘ãªã„ã»ã©è‰¯ã„ã€‚",
        "å„é …ç›®ã«ã¤ã„ã¦ã€ŒæˆåŠŸã€ã€Œè¦æ”¹å–„ã€ãªã©ã®æ˜ç¢ºãªè©•ä¾¡ã‚’ä¸‹ã—ã€ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸå…·ä½“çš„ãªæ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆã§ç· ã‚ããã£ã¦ãã ã•ã„ã€‚ã“ã‚Œã«ã‚ˆã‚Šæ„æ€æ±ºå®šã®æ¨™æº–åŒ–ã‚’å›³ã‚Šã¾ã™ã€‚",
        "\n---",
        "## åˆ†æãƒ‡ãƒ¼ã‚¿\n",
        f"**åˆ†ææœŸé–“:** {report_data.get('period_start')} ï½ {report_data.get('period_end')}\n",
        f"**å¯¾è±¡ãƒ•ãƒ­ã‚¢:** {report_data.get('floor_name')}\n",

        "### 1. æ¸©åº¦å®‰å®šæ€§\n",
        f"- å¾“æ¥åˆ¶å¾¡æ™‚ã®ç›®æ¨™æ¸©åº¦ã¨ã®å¹³å‡èª¤å·®: {report_data.get('temp_error_conv', 'N/A')} â„ƒ\n",
        f"- ALåˆ¶å¾¡æ™‚ã®ç›®æ¨™æ¸©åº¦ã¨ã®å¹³å‡èª¤å·®: {report_data.get('temp_error_al', 'N/A')} â„ƒ\n",

        "### 2. çœã‚¨ãƒåŠ¹æœ\n",
        f"- å¾“æ¥åˆ¶å¾¡æ™‚ã®æ—¥å¹³å‡é›»åŠ›æ¶ˆè²»é‡: {report_data.get('energy_conv_kwh', 'N/A')} kWh\n",
        f"- ALåˆ¶å¾¡æ™‚ã®æ—¥å¹³å‡é›»åŠ›æ¶ˆè²»é‡: {report_data.get('energy_al_kwh', 'N/A')} kWh\n",

        "### 3. åˆ¶å¾¡åŠ¹ç‡\n",
        f"- ALåˆ¶å¾¡ã®æˆåŠŸç‡ï¼ˆç©ºèª¿ç¨¼åƒæ™‚é–“ä¸­ï¼‰: {report_data.get('control_efficiency_rate', 'N/A')} %\n",

        "### 4. å¿«é©æ€§å‘ä¸Š\n",
        f"- å¾“æ¥åˆ¶å¾¡æ™‚ã®1æ—¥ã‚ãŸã‚Šå¹³å‡æ‰‹å‹•æ“ä½œå›æ•°: {report_data.get('manual_ops_conv', 'N/A')} å›\n",
        f"- ALåˆ¶å¾¡æ™‚ã®1æ—¥ã‚ãŸã‚Šå¹³å‡æ‰‹å‹•æ“ä½œå›æ•°: {report_data.get('manual_ops_al', 'N/A')} å›\n",
        "---",
        "\n## åˆ†æç”¨ã‚°ãƒ©ãƒ•\n",
        "ä»¥ä¸‹ã®ã‚°ãƒ©ãƒ•ã‚‚å‚è€ƒã«ã—ã¦åˆ†æã—ã¦ãã ã•ã„ã€‚",
    ]

    # ã‚°ãƒ©ãƒ•ç”»åƒã‚’è¿½åŠ 
    if graph_images.get('temperature_summary'):
        prompt_parts.append(graph_images.get('temperature_summary'))
    if graph_images.get('energy_scatter'):
        prompt_parts.append(graph_images.get('energy_scatter'))

    prompt_parts.append("\nä»¥ä¸Šã®æƒ…å ±ã«åŸºã¥ãã€ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")

    # ä¸è¦ãªNoneã‚’ãƒªã‚¹ãƒˆã‹ã‚‰é™¤å»
    prompt_parts_filtered = [part for part in prompt_parts if part is not None]

    try:
        st.info("Gemini APIã«ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ã¦ã„ã¾ã™...")
        response = model.generate_content(prompt_parts_filtered)
        return response.text
    except Exception as e:
        error_msg = f"Gemini APIå‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
        st.error(error_msg)
        return f"ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n\n{error_msg}"

def setup_japanese_font():
    """æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    try:
        # HeiseiKakuGo-W5ï¼ˆãƒ’ãƒ©ã‚®ãƒè§’ã‚´ Pro W3ã®ä»£æ›¿ï¼‰ã‚’è©¦ã™
        pdfmetrics.registerFont(UnicodeCIDFont('HeiseiKakuGo-W5'))
        return 'HeiseiKakuGo-W5'
    except:
        try:
            # HeiseiMin-W3ï¼ˆæ˜æœä½“ï¼‰ã‚’è©¦ã™
            pdfmetrics.registerFont(UnicodeCIDFont('HeiseiMin-W3'))
            return 'HeiseiMin-W3'
        except:
            try:
                # KozMinPro-Regularï¼ˆå°å¡šæ˜æœï¼‰ã‚’è©¦ã™
                pdfmetrics.registerFont(UnicodeCIDFont('KozMinPro-Regular'))
                return 'KozMinPro-Regular'
            except:
                # ã©ã®ãƒ•ã‚©ãƒ³ãƒˆã‚‚ä½¿ãˆãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨
                st.warning("æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                return 'Helvetica'

def convert_markdown_to_pdf(markdown_text, file_name):
    """Markdownãƒ†ã‚­ã‚¹ãƒˆã‚’PDFã«å¤‰æ›ã™ã‚‹é–¢æ•°"""
    try:
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        japanese_font = setup_japanese_font()
        
        # ãƒã‚¤ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ä½œæˆ
        buffer = io.BytesIO()
        
        # PDFæ–‡æ›¸ä½œæˆ
        doc = SimpleDocTemplate(buffer, pagesize=A4, topMargin=20*mm, bottomMargin=20*mm,
                              leftMargin=20*mm, rightMargin=20*mm)
        
        # ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
        styles = getSampleStyleSheet()
        
        # æ—¥æœ¬èªå¯¾å¿œã‚¹ã‚¿ã‚¤ãƒ«ä½œæˆ
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Title'],
            fontName=japanese_font,
            fontSize=16,
            spaceAfter=20,
            alignment=1  # ä¸­å¤®æƒãˆ
        )
        
        heading_style = ParagraphStyle(
            'CustomHeading',
            parent=styles['Heading1'],
            fontName=japanese_font,
            fontSize=14,
            spaceAfter=12,
            spaceBefore=12
        )
        
        normal_style = ParagraphStyle(
            'CustomNormal',
            parent=styles['Normal'],
            fontName=japanese_font,
            fontSize=10,
            spaceAfter=6,
            leading=14
        )
        
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é…åˆ—
        story = []
        
        # ã‚¿ã‚¤ãƒˆãƒ«è¿½åŠ 
        story.append(Paragraph("AirPlug ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µã‚¯ã‚»ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆ", title_style))
        story.append(Spacer(1, 20))
        
        # Markdownã‚’ç°¡å˜ãªHTMLã«å¤‰æ›ã—ã¦ãƒ‘ãƒ¼ã‚¹ã™ã‚‹
        lines = markdown_text.split('\n')
        current_paragraph = ""
        
        for line in lines:
            line = line.strip()
            
            if not line:
                if current_paragraph:
                    # æ®µè½çµ‚äº†
                    story.append(Paragraph(current_paragraph, normal_style))
                    current_paragraph = ""
                story.append(Spacer(1, 6))
                continue
            
            # è¦‹å‡ºã—å‡¦ç†
            if line.startswith('###'):
                if current_paragraph:
                    story.append(Paragraph(current_paragraph, normal_style))
                    current_paragraph = ""
                heading_text = line.replace('###', '').strip()
                story.append(Paragraph(heading_text, heading_style))
                continue
            elif line.startswith('##'):
                if current_paragraph:
                    story.append(Paragraph(current_paragraph, normal_style))
                    current_paragraph = ""
                heading_text = line.replace('##', '').strip()
                story.append(Paragraph(heading_text, heading_style))
                continue
            elif line.startswith('#'):
                if current_paragraph:
                    story.append(Paragraph(current_paragraph, normal_style))
                    current_paragraph = ""
                heading_text = line.replace('#', '').strip()
                story.append(Paragraph(heading_text, heading_style))
                continue
            
            # ç®‡æ¡æ›¸ãå‡¦ç†
            if line.startswith('- ') or line.startswith('* '):
                if current_paragraph:
                    story.append(Paragraph(current_paragraph, normal_style))
                    current_paragraph = ""
                bullet_text = "â€¢ " + line[2:].strip()
                story.append(Paragraph(bullet_text, normal_style))
                continue
            
            # é€šå¸¸ãƒ†ã‚­ã‚¹ãƒˆ
            if current_paragraph:
                current_paragraph += " "
            current_paragraph += line
        
        # æœ€å¾Œã®æ®µè½
        if current_paragraph:
            story.append(Paragraph(current_paragraph, normal_style))
        
        # PDFç”Ÿæˆ
        doc.build(story)
        
        # ãƒã‚¤ãƒˆé…åˆ—å–å¾—
        buffer.seek(0)
        return buffer.getvalue()
        
    except Exception as e:
        st.error(f"PDFå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def get_energy_data(params):
    """ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ï¼ˆãƒ‰ãƒ©ãƒƒã‚°ã‚¢ãƒ³ãƒ‰ãƒ‰ãƒ­ãƒƒãƒ—å¯¾å¿œï¼‰"""
    
    data_source = st.sidebar.radio(
        "ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’é¸æŠ",
        ["ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨", "ãƒ‡ãƒ¼ã‚¿ãªã—"]
    )
    
    if data_source == "ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
        st.sidebar.info("ğŸ’¡ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™")
        
        # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ã«ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã‚¨ãƒªã‚¢ã‚’ä½œæˆ
        with st.container():
            st.markdown("### ğŸ“ ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
            st.markdown("---")
            
            # ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã‚¨ãƒªã‚¢ã®ã‚¹ã‚¿ã‚¤ãƒ«
            drop_zone_style = """
            <style>
            .drop-zone {
                border: 3px dashed #cccccc;
                border-radius: 10px;
                padding: 50px;
                text-align: center;
                margin: 20px 0;
                background-color: #f8f9fa;
                transition: all 0.3s ease;
            }
            .drop-zone:hover {
                border-color: #007bff;
                background-color: #e7f3ff;
            }
            .drop-zone-active {
                border-color: #28a745;
                background-color: #d4edda;
            }
            </style>
            """
            st.markdown(drop_zone_style, unsafe_allow_html=True)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’å¤§ããªãƒ‰ãƒ­ãƒƒãƒ—ã‚¾ãƒ¼ãƒ³ã¨ã—ã¦è¡¨ç¤º
            col1, col2, col3 = st.columns([1, 3, 1])
            with col2:
                st.markdown("""
                <div class="drop-zone">
                    <h3>ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã“ã“ã«ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—</h3>
                    <p>ã¾ãŸã¯ä¸‹ã®ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ</p>
                    <p style="color: #666;">å¯¾å¿œå½¢å¼: CSV, Excel (.xlsx)</p>
                </div>
                """, unsafe_allow_html=True)
                
                uploaded_files = st.file_uploader(
                    "",
                    type=['csv', 'xlsx'],
                    accept_multiple_files=True,
                    key="drag_drop_uploader",
                    help="è¤‡æ•°ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã¾ãŸã¯ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ãã ã•ã„"
                )
        
        if uploaded_files:
            try:
                st.success(f"ğŸ‰ {len(uploaded_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸï¼")
                
                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°è¡¨ç¤º
                with st.expander("ğŸ“‹ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°", expanded=True):
                    file_details = []
                    total_size = 0
                    
                    for i, uploaded_file in enumerate(uploaded_files, 1):
                        file_size = len(uploaded_file.getvalue()) if hasattr(uploaded_file, 'getvalue') else 0
                        total_size += file_size
                        
                        file_details.append({
                            "No.": i,
                            "ãƒ•ã‚¡ã‚¤ãƒ«å": uploaded_file.name,
                            "ã‚µã‚¤ã‚º": f"{file_size/1024:.1f} KB" if file_size > 0 else "N/A",
                            "å½¢å¼": uploaded_file.name.split('.')[-1].upper()
                        })
                    
                    import pandas as pd
                    df_details = pd.DataFrame(file_details)
                    st.dataframe(df_details, use_container_width=True)
                    st.info(f"ğŸ“Š åˆè¨ˆ: {len(uploaded_files)}ãƒ•ã‚¡ã‚¤ãƒ«, {total_size/1024:.1f} KB")
                
                # Masterå½¢å¼çµ±ä¸€å¤‰æ›ã®å®Ÿè¡Œ
                with st.spinner("ğŸ”„ Masterå½¢å¼ã«å¤‰æ›ä¸­..."):
                    df_master = convert_to_master_format(uploaded_files, params['energy_format_type'])
                    
                    if df_master.shape[0] == 0:
                        st.warning("âš ï¸ æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                        return pl.DataFrame(), False
                    
                    # Polarsãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
                    combined_df = pl.DataFrame(df_master)
                    
                    st.success(f"âœ… Masterå½¢å¼ã¸ã®å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                    
                    # å¤‰æ›çµæœã®ã‚µãƒãƒªãƒ¼è¡¨ç¤º
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ğŸ“Š ãƒ‡ãƒ¼ã‚¿è¡Œæ•°", f"{combined_df.height:,}")
                    with col2:
                        st.metric("ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿åˆ—æ•°", combined_df.width)
                    with col3:
                        if 'DateTime' in combined_df.columns:
                            dt_range = combined_df.select([
                                pl.col('DateTime').min().alias('start'),
                                pl.col('DateTime').max().alias('end')
                            ]).to_pandas().iloc[0]
                            duration = pd.to_datetime(dt_range['end']) - pd.to_datetime(dt_range['start'])
                            st.metric("ğŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“", f"{duration.days}æ—¥")
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                    with st.expander("ğŸ‘€ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                        st.dataframe(combined_df.head(10).to_pandas(), use_container_width=True)
                    
                    return combined_df, True
                    
            except Exception as e:
                st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                st.code(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
                return pl.DataFrame(), False
        else:
            st.info("ğŸ‘† ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã¾ãŸã¯é¸æŠã—ã¦ãã ã•ã„")
            return pl.DataFrame(), False
    
    elif data_source == "è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
        st.sidebar.info("è¤‡æ•°ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™")
        
        uploaded_files = st.sidebar.file_uploader(
            "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¤‡æ•°é¸æŠ",
            type=['csv'],
            accept_multiple_files=True,
            help="è¤‡æ•°ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
        )
        
        if uploaded_files:
            try:
                # Masterå½¢å¼çµ±ä¸€å¤‰æ›ã‚’ä½¿ç”¨
                st.sidebar.info("ğŸ”„ Masterå½¢å¼ã«çµ±ä¸€å¤‰æ›ä¸­...")
                df_master = convert_to_master_format(uploaded_files, params['energy_format_type'])
                
                if df_master.shape[0] == 0:
                    st.sidebar.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                    return pl.DataFrame(), False
                
                # Polarsãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
                combined_df = pl.DataFrame(df_master)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
                file_info = []
                for uploaded_file in uploaded_files:
                    file_info.append({
                        'name': uploaded_file.name,
                        'size': len(uploaded_file.getvalue()) if hasattr(uploaded_file, 'getvalue') else 'N/A'
                    })
                
                st.sidebar.success(f"âœ… {len(uploaded_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Masterå½¢å¼ã§çµ±åˆã—ã¾ã—ãŸ")
                st.sidebar.info(f"ğŸ“Š çµ±åˆçµæœ: {combined_df.height}è¡Œ Ã— {combined_df.width}åˆ—")
                
                with st.sidebar.expander("ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°"):
                    for info in file_info:
                        st.write(f"ğŸ“„ {info['name']}")
                    st.write(f"ğŸ“ˆ å¤‰æ›å½¢å¼: {params['energy_format_type']} â†’ master")
                    if 'DateTime' in combined_df.columns:
                        dt_range = combined_df.select([
                            pl.col('DateTime').min().alias('start'),
                            pl.col('DateTime').max().alias('end')
                        ]).to_pandas().iloc[0]
                        st.write(f"ğŸ“… æœŸé–“: {dt_range['start']} ï½ {dt_range['end']}")
                
                return combined_df, True
                
            except Exception as e:
                st.sidebar.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                return pl.DataFrame(), False
        else:
            st.sidebar.info("è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
            return pl.DataFrame(), False
    
    elif data_source == "å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
        uploaded_file = st.sidebar.file_uploader(
            "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['csv'],
            help="master.csv ã¾ãŸã¯åŒç­‰ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
        )
        
        if uploaded_file:
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã«å¿œã˜ãŸèª­ã¿è¾¼ã¿å‡¦ç†
                if params['energy_format_type'] == 'hioki':
                    energy_df = pl.read_csv(uploaded_file, skip_rows=26, null_values=["-"])[:, 3:]
                elif params['energy_format_type'] == 'master':
                    energy_df = pl.read_csv(uploaded_file, null_values=["-"])[:, 2:]
                else:
                    energy_df = pl.read_csv(uploaded_file, null_values=["-"])
                
                st.sidebar.success(f"âœ… {uploaded_file.name} ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                return energy_df, True
            except Exception as e:
                st.sidebar.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                return pl.DataFrame(), False
        else:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„å ´åˆ
            st.sidebar.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ä»–ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’é¸æŠã—ã¦ãã ã•ã„")
            return pl.DataFrame(), False
    
    elif data_source == "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨":
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
        st.sidebar.info("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™")
        return generate_sample_energy_data(params), True
    
    else:
        st.sidebar.info("ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ãªã—ã§åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™")
        return pl.DataFrame(), False

def generate_sample_energy_data(params):
    """ã‚µãƒ³ãƒ—ãƒ«ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ"""
    # æœŸé–“ã«å¿œã˜ãŸã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    start = params['st_dt_ymdhms']
    end = params['ed_dt_ymdhms']
    
    # 1æ™‚é–“ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    date_range = pd.date_range(start=start, end=end, freq='1H')
    
    # ãƒ©ãƒ³ãƒ€ãƒ ãªã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿
    np.random.seed(42)
    data = {
        'DateTime': [dt.strftime('%Y-%m-%d %H:%M:%S') for dt in date_range],
        'CH1(kW)': np.random.uniform(10, 50, len(date_range)),
        'CH2(kW)': np.random.uniform(5, 30, len(date_range)),
        'CH3(kW)': np.random.uniform(15, 40, len(date_range))
    }
    
    return pl.DataFrame(data)

# ================================
# ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿å½¢å¼çµ±ä¸€æ©Ÿèƒ½
# ================================

def clean_column_names(df, meta_columns=['ãƒšãƒ¼ã‚¸No', 'æ—¥ä»˜', 'æ™‚åˆ»']):
    """å…ˆé ­è¡Œã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã—ã¦åˆ©ç”¨ã—ã€ãƒ¡ã‚¿æƒ…å ±åˆ—ä»¥é™ã‚’è‡ªå‹•ã§CHã‚«ãƒ©ãƒ åã«å¤‰æ›"""
    if df.shape[0] == 0:
        return df
    
    df.columns = df.iloc[0]
    df = df.drop(0).reset_index(drop=True)
    num_measurements = df.shape[1] - len(meta_columns)
    measurement_columns = [f'CH{i+1}(kW)' for i in range(num_measurements)]
    new_columns = meta_columns + measurement_columns
    
    if len(df.columns) < len(new_columns):
        new_columns = new_columns[:len(df.columns)]
    
    df.columns = new_columns
    df = df.dropna(how='all').reset_index(drop=True)
    return df

def expand_to_minutely(df, meta_columns=['ãƒšãƒ¼ã‚¸No', 'æ—¥ä»˜', 'æ™‚åˆ»'], offset=0):
    """å„è¡Œã«ã¤ã„ã¦ã€æ—¥ä»˜ãƒ»æ™‚åˆ»ã‚’å…ƒã«1åˆ†åˆ»ã¿ã§60è¡Œã«å±•é–‹"""
    if df.shape[0] == 0:
        return df
    
    expanded_rows = []
    measurement_columns = [col for col in df.columns if col not in meta_columns]
    
    for index, row in df.iterrows():
        try:
            date = pd.to_datetime(row['æ—¥ä»˜'], errors='coerce')
            time = pd.to_datetime(row['æ™‚åˆ»'], format='%H:%M', errors='coerce')
            if pd.isnull(date) or pd.isnull(time):
                continue
            
            datetime_combined = datetime.datetime.combine(date.date(), time.time())
            datetime_combined = datetime_combined - datetime.timedelta(minutes=offset)
            
            for minute in range(60):
                new_datetime = datetime_combined + datetime.timedelta(minutes=minute)
                new_row = {
                    'No.': len(expanded_rows) + 1,
                    'Date': new_datetime.strftime('%Y-%m-%d'),
                    'Time': new_datetime.strftime('%H:%M:%S'),
                    'DateTime': new_datetime.strftime('%Y-%m-%d %H:%M:%S')
                }
                for col in measurement_columns:
                    new_row[col] = row[col]
                expanded_rows.append(new_row)
        except Exception as e:
            print(f"Error processing row {index}: {e}")
    
    return pd.DataFrame(expanded_rows)

def convert_dk_format(df):
    """dkï¼ˆé‡æ‘ä¸å‹•ç”£ï¼‰ç”¨ã®ã€Œæ—¥æ™‚ã€åˆ—ã‹ã‚‰1æ™‚é–“åˆ†ã‚’1åˆ†åˆ»ã¿å±•é–‹"""
    if df.shape[0] == 0:
        return df
    
    power_columns = [col for col in df.columns if "é›»åŠ›" in col]
    if len(power_columns) == 0:
        return pd.DataFrame()
    
    expanded_rows = []
    record_no = 1
    
    for idx, row in df.iterrows():
        dt = pd.to_datetime(row.get("æ—¥æ™‚", None), format="%Y/%m/%d %H:%M:%S", errors="coerce")
        if pd.isnull(dt):
            continue
        
        for minute in range(60):
            new_dt = dt + datetime.timedelta(minutes=minute)
            new_row = {
                "No.": record_no,
                "Date": new_dt.strftime("%Y-%m-%d"),
                "Time": new_dt.strftime("%H:%M:%S"),
                "DateTime": new_dt.strftime("%Y-%m-%d %H:%M:%S")
            }
            for i, col in enumerate(power_columns, start=1):
                new_row[f"CH{i}(kW)"] = row[col]
            expanded_rows.append(new_row)
            record_no += 1
    
    return pd.DataFrame(expanded_rows)

def process_mufg(uploaded_files):
    """MUFGå½¢å¼ã®è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦masterå½¢å¼ã«å¤‰æ›ï¼ˆcsv_to_masterä»•æ§˜ï¼‰"""
    print('â–¼ process_mufg start â–¼')
    
    dfs = []
    for uploaded_file in uploaded_files:
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚’å–å¾—
            temp = pd.read_csv(uploaded_file, encoding='cp932', on_bad_lines='skip', nrows=1)
            day = temp.columns[1] if len(temp.columns) > 1 else None
            
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, encoding='cp932', skiprows=8)
            
            # ã‚«ãƒ©ãƒ å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            if 'å˜ä½' in df.columns:
                df = df.rename(columns={'å˜ä½': 'Time'})
            else:
                time_column = next((col for col in df.columns if "time" in col.lower() or "æ™‚åˆ»" in col.lower()), None)
                if time_column:
                    df = df.rename(columns={time_column: 'Time'})
                else:
                    print(f"No suitable time column in {uploaded_file.name}, skipping...")
                    continue
            
            df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
            measurement_columns = [col for col in df.columns if col not in ['Date','Time']]
            mapping = {old: f"CH{i+1}(kW)" for i, old in enumerate(measurement_columns)}
            df = df.rename(columns=mapping)
            df['Date'] = day
            
            df = df[df['Time'].astype(str).str.match(r'^\d{1,2}:\d{2}')]
            df['Time'] = df['Time'].str.replace('24:00', '00:00')
            df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], errors='coerce', format='%Y/%m/%d %H:%M')
            
            channel_names = [f"CH{i+1}(kW)" for i in range(len(measurement_columns))]
            new_columns = ['Date', 'Time', 'DateTime'] + channel_names
            df = df[new_columns].dropna(subset=['DateTime'])
            
            dfs.append(df)
            
        except Exception as e:
            print(f"Error reading file {uploaded_file.name}: {e}")
            continue
    
    if len(dfs) == 0:
        print("No valid MUFG dataframes found.")
        return pd.DataFrame()
    
    combined_df = pd.concat(dfs, ignore_index=True)
    # 1åˆ†åˆ»ã¿ãƒªã‚µãƒ³ãƒ—ãƒ«
    combined_df = combined_df.set_index('DateTime').resample('1min').ffill().reset_index()
    combined_df['Date'] = combined_df['DateTime'].dt.strftime('%Y-%m-%d')
    combined_df['Time'] = combined_df['DateTime'].dt.strftime('%H:%M:%S')
    
    meta_columns = ['Date', 'Time', 'DateTime']
    measurement_columns = [col for col in combined_df.columns if col not in meta_columns]
    combined_df = combined_df[meta_columns + measurement_columns]
    
    print('â–² process_mufg end â–²')
    return combined_df

def process_RPT(uploaded_files):
    """RPTå½¢å¼ã®è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦masterå½¢å¼ã«å¤‰æ›ï¼ˆcsv_to_masterä»•æ§˜ï¼‰"""
    print('â–¼ process_RPT start â–¼')
    
    dataframes = []
    for uploaded_file in uploaded_files:
        try:
            df = pd.read_csv(uploaded_file, encoding='cp932')
            df = df.iloc[7:32, :7].reset_index(drop=True)
            dataframes.append(df)
        except Exception as e:
            print(f"Error reading file {uploaded_file.name}: {e}")
            continue
    
    if len(dataframes) == 0:
        print("No valid RPT dataframes found.")
        return pd.DataFrame()
    
    combined_df = pd.concat(dataframes, axis=0).reset_index(drop=True)
    cleaned_df = clean_column_names(combined_df)
    minutely_df = expand_to_minutely(cleaned_df, offset=0)
    
    print('â–² process_RPT end â–²')
    return minutely_df

def process_hioki_cloud(uploaded_files):
    """HIOKI Cloudå½¢å¼ã®è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦masterå½¢å¼ã«å¤‰æ›ï¼ˆcsv_to_masterä»•æ§˜ï¼‰"""
    print('â–¼ process_hioki_cloud start â–¼')
    
    dataframes = []
    for uploaded_file in uploaded_files:
        try:
            df = pd.read_csv(uploaded_file, encoding="cp932", on_bad_lines='skip', header=None, skiprows=26)
            df = df.iloc[:, :6]  # æœ€åˆ6åˆ—ã‚’æƒ³å®š
            dataframes.append(df)
        except Exception as e:
            print(f"Error reading file {uploaded_file.name}: {e}")
            continue
    
    if len(dataframes) == 0:
        print("No valid hioki_cloud dataframes found.")
        return pd.DataFrame()
    
    combined_df = pd.concat(dataframes, axis=0).reset_index(drop=True)
    cleaned_df = clean_column_names(combined_df)
    minutely_df = expand_to_minutely(cleaned_df, offset=0)
    
    print('â–² process_hioki_cloud end â–²')
    return minutely_df

def process_dk(uploaded_files):
    """DKå½¢å¼ã®è¤‡æ•°Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦masterå½¢å¼ã«å¤‰æ›ï¼ˆcsv_to_masterä»•æ§˜ï¼‰"""
    print('â–¼ process_dk start â–¼')
    
    dataframes = []
    for uploaded_file in uploaded_files:
        try:
            if uploaded_file.name.endswith('.xlsx'):
                df = pd.read_excel(uploaded_file, sheet_name='Outdoor', skiprows=6)
            else:
                df = pd.read_csv(uploaded_file)
            dataframes.append(df)
        except Exception as e:
            print(f"Error reading file {uploaded_file.name}: {e}")
            continue
    
    if len(dataframes) == 0:
        print("No valid dk dataframes found.")
        return pd.DataFrame()
    
    combined_df = pd.concat(dataframes, axis=0).reset_index(drop=True)
    result_df = convert_dk_format(combined_df)
    
    if result_df.shape[0] > 0 and "No." in result_df.columns:
        result_df = result_df.drop(columns=["No."])
    
    print('â–² process_dk end â–²')
    return result_df

def process_hioki_local(uploaded_files):
    """HIOKI Localå½¢å¼ã®è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦masterå½¢å¼ã«å¤‰æ›ï¼ˆcsv_to_masterä»•æ§˜ï¼‰"""
    print('â–¼ process_hioki_local start â–¼')
    
    dataframes = []
    
    for i, uploaded_file in enumerate(uploaded_files):
        try:
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
            metadata = pd.read_csv(uploaded_file, encoding='cp932', header=None, nrows=6)
            trigger_date = None
            if metadata.shape[0] >= 6 and pd.notna(metadata.iloc[5, 1]):
                trigger_time = str(metadata.iloc[5, 1])
                trigger_date = trigger_time.split()[0]
            
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, encoding='cp932', skiprows=11)
            print(f"Data shape after reading CSV: {df.shape}")
            
            df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
            
            time_column = next((col for col in df.columns if "time" in col.lower()), None)
            if not time_column:
                continue
            if time_column != 'Time':
                df = df.rename(columns={time_column: 'Time'})
            
            df['DateTime'] = pd.to_datetime(df['Time'], errors='coerce', format='%Y/%m/%d %H:%M:%S')
            if df['DateTime'].isna().all():
                df['DateTime'] = pd.to_datetime(df['Time'], errors='coerce')
            
            if trigger_date is not None:
                mask = df['DateTime'].isna()
                if mask.any():
                    df.loc[mask, 'DateTime'] = pd.to_datetime(trigger_date + ' ' + df.loc[mask, 'Time'], errors='coerce')
            
            df = df.dropna(subset=['DateTime'])
            # ç§’æ•°ã‚’0ã«çµ±ä¸€ï¼ˆåˆ†å˜ä½ã«ä¸¸ã‚ã‚‹ï¼‰ï¼šç§’ãŒãƒ•ã‚¡ã‚¤ãƒ«æ¯ã«ãƒãƒ©ãƒãƒ©ãªãŸã‚
            df['DateTime'] = df['DateTime'].dt.floor('min')
            df['Date'] = df['DateTime'].dt.strftime('%Y-%m-%d')
            df['Time'] = df['DateTime'].dt.strftime('%H:%M:%S')
            
            measurement_cols = [col for col in df.columns if col not in ['Date', 'Time', 'DateTime']]
            if len(measurement_cols) < 2:
                print(f"{uploaded_file.name} ã«ã¯æœ€ä½2ã¤ã®è¨ˆæ¸¬åˆ—ãŒå¿…è¦ã§ã™ã€‚Skipping...")
                continue
            
            # â–¼é›»æµã‚’é›»åœ§ã«å¤‰æ›
            df = df.rename(columns={measurement_cols[0]: 'CH1', measurement_cols[1]: 'CH2'})
            
            # W_kW ã®è¨ˆç®—
            V = 205
            cos_theta = 0.95
            # å¼: W = âˆš3 Ã— ((VÃ—CH1 + VÃ—CH2)/2) Ã— cosÎ¸, ãã®å¾Œ kW å˜ä½ã« (W/1000)
            df['W_kW'] = (math.sqrt(3) * ((V * df['CH1']) + (V * df['CH2'])) / 2 * cos_theta) / 1000
            
            new_col_name = f"CH{i+1}(kW)"
            df = df[['Date', 'Time', 'DateTime', 'W_kW']].rename(columns={'W_kW': new_col_name})
            df = df.drop_duplicates(subset='DateTime')
            # â–²é›»æµã‚’é›»åœ§ã«å¤‰æ›
            
            dataframes.append(df)
            
        except Exception as e:
            print(f"Error reading file {uploaded_file.name}: {e}")
            continue
    
    if len(dataframes) == 0:
        return pd.DataFrame()
    
    combined_df = dataframes[0].set_index('DateTime')
    for j in range(1, len(dataframes)):
        df_j = dataframes[j].set_index('DateTime')
        df_j = df_j.drop(columns=['Date', 'Time'])
        combined_df = combined_df.join(df_j, how='outer')
    
    combined_df = combined_df.sort_index().reset_index()
    combined_df['Date'] = combined_df['DateTime'].dt.strftime('%Y-%m-%d')
    combined_df['Time'] = combined_df['DateTime'].dt.strftime('%H:%M:%S')
    
    meta_cols = ['Date', 'Time', 'DateTime']
    measurement_cols = [col for col in combined_df.columns if col not in meta_cols]
    combined_df = combined_df[meta_cols + measurement_cols]
    
    print('â–² process_hioki_local end â–²')
    return combined_df

def reorder_columns(df):
    """
    ã‚«ãƒ©ãƒ ã‚’ [Date, Time, DateTime, CH1(kW), CH2(kW), ...] ã®é †ç•ªã«ã™ã‚‹ï¼ˆcsv_to_masterä»•æ§˜ï¼‰
    ã‚‚ã—è©²å½“ã‚«ãƒ©ãƒ ãŒç„¡ã„å ´åˆã¯ç„¡è¦–ã—ã€å­˜åœ¨ã™ã‚‹åˆ†ã ã‘é †åºã‚’åˆã‚ã›ã‚‹ã€‚
    ä»–ã®ã‚«ãƒ©ãƒ ãŒå«ã¾ã‚Œã¦ã„ã¦ã‚‚æœ€å¾Œã«å›ã™ã‹ã€å¿…è¦ã«å¿œã˜ã¦å‰Šé™¤ã™ã‚‹ã€‚
    """
    if df.shape[0] == 0:
        return df
    
    # 1) å¿…é ˆã®ãƒ¡ã‚¿ã‚«ãƒ©ãƒ 
    meta_cols = ['Date', 'Time', 'DateTime']
    
    # 2) CHn(kW) ã‚«ãƒ©ãƒ ã‚’æ¢ã—ã¦ä¸¦ã³æ›¿ãˆ
    #    ä¾‹: "CH1(kW)" -> 1, "CH11(kW)" -> 11
    ch_cols = [col for col in df.columns if col.startswith('CH') and col.endswith('(kW)')]
    def extract_ch_number(col_name):
        # "CH1(kW)" -> "1", "CH11(kW)" -> "11"
        return int(col_name[2:].split('(')[0])
    
    ch_cols_sorted = sorted(ch_cols, key=extract_ch_number)
    
    # 3) ä¸Šè¨˜ä»¥å¤–ã®ã‚«ãƒ©ãƒ ã¯ remainder ã¨ã—ã¦æœ€å¾Œã«
    remainder = [c for c in df.columns if c not in meta_cols + ch_cols]
    
    # 4) çµåˆã—ã¦å¿…è¦ãªé †ã«ã€‚å­˜åœ¨ã—ãªã„ã‚«ãƒ©ãƒ ã¯è‡ªå‹•çš„ã«ã‚¹ã‚­ãƒƒãƒ—ã€‚
    desired_order = meta_cols + ch_cols_sorted + remainder
    # å®Ÿéš›ã« df ã«å­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ ã ã‘å–ã‚Šå‡ºã™
    final_cols = [c for c in desired_order if c in df.columns]
    
    return df[final_cols]

def convert_to_master_format(uploaded_files, format_type):
    """è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’masterå½¢å¼ã«çµ±ä¸€å¤‰æ›ï¼ˆcsv_to_masterä»•æ§˜æº–æ‹ ï¼‰"""
    try:
        print(f"Processing {len(uploaded_files)} files with format: {format_type}")
        
        # å˜ä¸€ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†ã‚’å®Ÿè¡Œï¼ˆcsv_to_masterä»•æ§˜ï¼‰
        if format_type == 'mufg':
            df_master = process_mufg(uploaded_files)
        elif format_type == 'PRT':
            df_master = process_RPT(uploaded_files)
        elif format_type == 'hioki_local':
            df_master = process_hioki_local(uploaded_files)
        elif format_type == 'hioki_cloud':
            df_master = process_hioki_cloud(uploaded_files)
        elif format_type == 'dk':
            df_master = process_dk(uploaded_files)
        else:
            print(f"Unknown format: {format_type}, using generic processing...")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ï¼ˆæ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã®äº’æ›æ€§ï¼‰
            combined_df = pl.DataFrame()
            for uploaded_file in uploaded_files:
                try:
                    if uploaded_file.name.endswith('.xlsx'):
                        df_excel = pd.read_excel(uploaded_file)
                        energy_df = pl.DataFrame(df_excel)
                    else:
                        if format_type == 'hioki':
                            energy_df = pl.read_csv(uploaded_file, skip_rows=26, null_values=["-"])[:, 3:]
                        elif format_type == 'master':
                            energy_df = pl.read_csv(uploaded_file, null_values=["-"])[:, 2:]
                        else:
                            energy_df = pl.read_csv(uploaded_file, null_values=["-"])
                    
                    if combined_df.is_empty():
                        combined_df = energy_df
                    else:
                        if 'DateTime' in energy_df.columns and 'DateTime' in combined_df.columns:
                            combined_df = combined_df.join(energy_df, on='DateTime', how='outer')
                except Exception as e:
                    print(f"Error processing file {uploaded_file.name}: {e}")
                    continue
            
            df_master = combined_df.to_pandas()
        
        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ç©ºã®DataFrameã‚’è¿”ã™
        if df_master is None or df_master.shape[0] == 0:
            print("No valid data found. Creating empty DataFrame.")
            return pd.DataFrame()
        
        # ã‚«ãƒ©ãƒ ä¸¦ã³æ›¿ãˆ (Date, Time, DateTime, CH..., ãã®ä»–)
        df_master = reorder_columns(df_master)
        
        # DateTime ã§ã‚½ãƒ¼ãƒˆ
        if 'DateTime' in df_master.columns:
            df_master = df_master.sort_values('DateTime')
        
        # æ•°å€¤ã‚«ãƒ©ãƒ ã‚’ Float64 ã«å¤‰æ›ã—ã€nullå€¤ã‚’0ã§åŸ‹ã‚ã‚‹ï¼ˆcsv_to_masterä»•æ§˜ï¼‰
        cols_to_convert = [col for col in df_master.columns if col not in ["DateTime", "Date", "Time"]]
        # Use polars to convert columns to Float64 and fill nulls with 0
        df_master = pl.DataFrame(df_master).with_columns(
            [pl.col(col).cast(pl.Float64).fill_null(0) for col in cols_to_convert]
        ).to_pandas()
        
        print(f"Master CSV conversion completed. Shape: {df_master.shape}")
        return df_master
        
    except Exception as e:
        st.error(f"Masterå½¢å¼å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"Error in convert_to_master_format: {e}")
        return pd.DataFrame()

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        st.code(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
